{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28bea13b-67bd-4a0e-8eab-3b8ffd37259e",
   "metadata": {},
   "source": [
    "# TorQ: Create Everything\n",
    "This notebook will use the AWS boto3 APIs to create the needed resources for a TorQ based application. The notebook will first clone the relevant gihub code (TorQ and TorQ AMazon FinSpace Starter Pack) then proceed to create the necessary AWS resources. \n",
    "\n",
    "Once you have create all clusters, you can see how to query for data through the gateway, see the [pykx_query_all](pykx_query_all.ipynb) notebook\n",
    "\n",
    "To cleanup (delete) all resources, run the [delete_all](delete_all.ipynb) notebook.\n",
    "\n",
    "## AWS Resources Created\n",
    "- Database   \n",
    "- Changeset to add data to database   \n",
    "- Scaling Group that will contain all clusters   \n",
    "- Shared Volume   \n",
    "- Dataview of database on the shared volume   \n",
    "- Clusters\n",
    "\n",
    "This notebook is based on the TorQ Amazon FinSpace starter pack but uses Scaling Groups and Shared Volumes for cost savings.\n",
    "\n",
    "[TorQ Amazon FinSpace Starter Pack](https://dataintellecttech.github.io/TorQ-Amazon-FinSpace-Starter-Pack/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c036169-ee58-48d0-a20e-f95364a6adf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘torq_app.zip’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm torq_app.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1f6438f-d994-4956-82a8-6c6dc720da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf TorQ TorQ-Amazon-FinSpace-Starter-Pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c462e93-8db0-4817-8ba3-72540fa878a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'TorQ'...\n",
      "remote: Enumerating objects: 793, done.\u001b[K\n",
      "remote: Counting objects: 100% (793/793), done.\u001b[K\n",
      "remote: Compressing objects: 100% (546/546), done.\u001b[K\n",
      "remote: Total 793 (delta 195), reused 595 (delta 174), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (793/793), 5.62 MiB | 31.82 MiB/s, done.\n",
      "Resolving deltas: 100% (195/195), done.\n"
     ]
    }
   ],
   "source": [
    "!git -c advice.detachedHead=false clone --depth 1 --branch v5.0.2 https://github.com/DataIntellectTech/TorQ.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e1d1c29-1253-446d-9baa-5d6c7f2f88c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'TorQ-Amazon-FinSpace-Starter-Pack'...\n",
      "remote: Enumerating objects: 158, done.\u001b[K\n",
      "remote: Counting objects: 100% (158/158), done.\u001b[K\n",
      "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
      "remote: Total 158 (delta 41), reused 118 (delta 36), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (158/158), 32.94 MiB | 41.54 MiB/s, done.\n",
      "Resolving deltas: 100% (41/41), done.\n"
     ]
    }
   ],
   "source": [
    "!git -c advice.detachedHead=false clone --depth 1 --branch  v1.0.1 https://github.com/DataIntellectTech/TorQ-Amazon-FinSpace-Starter-Pack.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b2b0ba1-3169-47d2-a445-243686a91cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s ../finspace_torq.q TorQ-Amazon-FinSpace-Starter-Pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d5f1d4a-ed45-44e3-bf75-9bdb75fcddbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import boto3\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import pykx as kx\n",
    "\n",
    "from managed_kx import *\n",
    "from env import *\n",
    "\n",
    "from clusters import *\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "TORQ_CODEBASE=\"TorQ\"\n",
    "TORQ_FINSPACE_CODEBASE=\"TorQ-Amazon-FinSpace-Starter-Pack\"\n",
    "\n",
    "SCALING_GROUP_NAME=\"SCALING_GROUP_torq\"\n",
    "\n",
    "VOLUME_NAME=\"SHARED_torq\"\n",
    "\n",
    "# Managed KX Databases\n",
    "DB_NAME=\"finspace-database\"\n",
    "\n",
    "DBVIEW_NAME=f\"{DB_NAME}_DBVIEW\"\n",
    "\n",
    "# Source data directory\n",
    "SOURCE_DATA_DIR=f\"{TORQ_FINSPACE_CODEBASE}/hdb\"\n",
    "\n",
    "# Code directory\n",
    "CODEBASE=\"torq_app\"\n",
    "\n",
    "# S3 Destinations\n",
    "S3_CODE_PATH=\"code\"\n",
    "S3_DATA_PATH=\"data\"\n",
    "\n",
    "NODE_TYPE=\"kx.sg.4xlarge\"\n",
    "\n",
    "DATABASE_CONFIG=[{ \n",
    "    'databaseName': DB_NAME,\n",
    "    'dataviewName': DBVIEW_NAME\n",
    "    }]\n",
    "CODE_CONFIG={ 's3Bucket': S3_BUCKET, 's3Key': f'{S3_CODE_PATH}/{CODEBASE}.zip' }\n",
    "\n",
    "NAS1_CONFIG= {\n",
    "        'type': 'SSD_250',\n",
    "        'size': 1200\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cfe7d89-9f5d-4ceb-ac8c-1f5054a6f15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using variables ...\n"
     ]
    }
   ],
   "source": [
    "# triggers credential get\n",
    "session=None\n",
    "\n",
    "if AWS_ACCESS_KEY_ID is None:\n",
    "    print(\"Using Defaults ...\")\n",
    "    # create AWS session: using access variables\n",
    "    session = boto3.Session()\n",
    "else:\n",
    "    print(\"Using variables ...\")\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "        aws_session_token=AWS_SESSION_TOKEN\n",
    "    )\n",
    "\n",
    "# create finspace client\n",
    "client = session.client(service_name='finspace', endpoint_url=ENDPOINT_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3d4047-9583-4b09-b75d-98fd2ddd6c36",
   "metadata": {},
   "source": [
    "# Create the Database\n",
    "Create a database from the supplied data in hdb.tar.gz.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf690f2-c465-4df8-90f5-1e3b808bb368",
   "metadata": {},
   "source": [
    "## Stage HDB Data on S3\n",
    "Using AWS cli, copy hdb to staging bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aca7f0d7-32cd-443b-b642-e7209b8516ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE 2014.04.21/\n",
      "                           PRE 2014.04.22/\n",
      "                           PRE 2014.04.23/\n",
      "2024-03-01 20:40:58         57 sym\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S3_DEST=f\"s3://{S3_BUCKET}/{S3_DATA_PATH}/{SOURCE_DATA_DIR}/\"\n",
    "\n",
    "if AWS_ACCESS_KEY_ID is not None:\n",
    "    cp = f\"\"\"\n",
    "export AWS_ACCESS_KEY_ID={AWS_ACCESS_KEY_ID}\n",
    "export AWS_SECRET_ACCESS_KEY={AWS_SECRET_ACCESS_KEY}\n",
    "export AWS_SESSION_TOKEN={AWS_SESSION_TOKEN}\n",
    "\n",
    "aws s3 sync --quiet --exclude .DS_Store {SOURCE_DATA_DIR} {S3_DEST}\n",
    "aws s3 ls {S3_DEST}\n",
    "\"\"\"\n",
    "else:\n",
    "    cp = f\"\"\"\n",
    "aws s3 sync --quiet --exclude .DS_Store {SOURCE_DATA_DIR} {S3_DEST}\n",
    "aws s3 ls {S3_DEST}\n",
    "\"\"\"\n",
    "    \n",
    "# execute the S3 copy\n",
    "os.system(cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c759c4-ee6c-45c5-a9f6-6acacea3a3be",
   "metadata": {},
   "source": [
    "## Create Managed Database\n",
    "Using the AWS APIs, create a managed database in Managed kdb Insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d55bd8d3-5629-46f9-bc1f-47bb0308dc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING Database: finspace-database\n",
      "CREATED Database: finspace-database\n",
      "{\n",
      "    \"createdTimestamp\": \"2024-03-01 20:40:58.628000+00:00\",\n",
      "    \"databaseArn\": \"arn:aws:finspace:us-east-1:829845998889:kxEnvironment/jlcenjvtkgzrdek2qqv7ic/kxDatabase/finspace-database\",\n",
      "    \"databaseName\": \"finspace-database\",\n",
      "    \"description\": \"Basictick kdb database\",\n",
      "    \"environmentId\": \"jlcenjvtkgzrdek2qqv7ic\",\n",
      "    \"lastModifiedTimestamp\": \"2024-03-01 20:40:58.628000+00:00\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# assume it exists\n",
    "create_db=False\n",
    "\n",
    "try:\n",
    "    resp = client.get_kx_database(environmentId=ENV_ID, databaseName=DB_NAME)\n",
    "    resp.pop('ResponseMetadata', None)\n",
    "except:\n",
    "    # does not exist, will create\n",
    "    create_db=True\n",
    "\n",
    "if create_db:\n",
    "    print(f\"CREATING Database: {DB_NAME}\")\n",
    "    resp = client.create_kx_database(environmentId=ENV_ID, databaseName=DB_NAME, description=\"Basictick kdb database\")\n",
    "    resp.pop('ResponseMetadata', None)\n",
    "\n",
    "    print(f\"CREATED Database: {DB_NAME}\")\n",
    "\n",
    "print(json.dumps(resp,sort_keys=True,indent=4,default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d1194e-0c04-49a3-a7e7-a1d23fcff0d9",
   "metadata": {},
   "source": [
    "## Add HDB Data to Database\n",
    "Add the data in the local hdb directory to the managed database using the changeset mechanism. The Data will be copied to S3 then ingested with the create-kx-changeset API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eae61f04-1c9c-468e-bb38-b2e0b94897a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changeset...\n",
      "{\n",
      "    \"changeRequests\": [\n",
      "        {\n",
      "            \"changeType\": \"PUT\",\n",
      "            \"dbPath\": \"/2014.04.21/\",\n",
      "            \"s3Path\": \"s3://kdb-demo-829845998889-kms/data/TorQ-Amazon-FinSpace-Starter-Pack/hdb/2014.04.21/\"\n",
      "        },\n",
      "        {\n",
      "            \"changeType\": \"PUT\",\n",
      "            \"dbPath\": \"/2014.04.22/\",\n",
      "            \"s3Path\": \"s3://kdb-demo-829845998889-kms/data/TorQ-Amazon-FinSpace-Starter-Pack/hdb/2014.04.22/\"\n",
      "        },\n",
      "        {\n",
      "            \"changeType\": \"PUT\",\n",
      "            \"dbPath\": \"/2014.04.23/\",\n",
      "            \"s3Path\": \"s3://kdb-demo-829845998889-kms/data/TorQ-Amazon-FinSpace-Starter-Pack/hdb/2014.04.23/\"\n",
      "        },\n",
      "        {\n",
      "            \"changeType\": \"PUT\",\n",
      "            \"dbPath\": \"/\",\n",
      "            \"s3Path\": \"s3://kdb-demo-829845998889-kms/data/TorQ-Amazon-FinSpace-Starter-Pack/hdb/sym\"\n",
      "        }\n",
      "    ],\n",
      "    \"changesetId\": \"9sb939X2p1mpLa97bptOTg\",\n",
      "    \"createdTimestamp\": \"2024-03-01 20:40:59.119000+00:00\",\n",
      "    \"databaseName\": \"finspace-database\",\n",
      "    \"environmentId\": \"jlcenjvtkgzrdek2qqv7ic\",\n",
      "    \"lastModifiedTimestamp\": \"2024-03-01 20:40:59.119000+00:00\",\n",
      "    \"status\": \"PENDING\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "changes=[]\n",
    "\n",
    "for f in os.listdir(f\"{SOURCE_DATA_DIR}\"):\n",
    "    if os.path.isdir(f\"{SOURCE_DATA_DIR}/{f}\"):\n",
    "        changes.append( { 'changeType': 'PUT', 's3Path': f\"{S3_DEST}{f}/\", 'dbPath': f\"/{f}/\" } )\n",
    "    else:\n",
    "        changes.append( { 'changeType': 'PUT', 's3Path': f\"{S3_DEST}{f}\", 'dbPath': f\"/\" } )\n",
    "        \n",
    "resp = client.create_kx_changeset(environmentId=ENV_ID, databaseName=DB_NAME, \n",
    "    changeRequests=changes)\n",
    "\n",
    "resp.pop('ResponseMetadata', None)\n",
    "changeset_id = resp['changesetId']\n",
    "\n",
    "print(\"Changeset...\")\n",
    "print(json.dumps(resp,sort_keys=True,indent=4,default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4422bdd-7d44-4fb0-8018-0bebd6987704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status is IN_PROGRESS, total wait 0:00:00, waiting 10 sec ...\n",
      "**Done**\n"
     ]
    }
   ],
   "source": [
    "wait_for_changeset_status(client, environmentId=ENV_ID, databaseName=DB_NAME, changesetId=changeset_id, show_wait=True)\n",
    "print(\"**Done**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ba008f3-4991-474c-9b3e-43a1dca56257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Database: finspace-database, Changesets: 1 \n",
      "====================================================================================================\n",
      "  Changeset: 9sb939X2p1mpLa97bptOTg: Created: 2024-03-01 20:40:59.119000+00:00 (COMPLETED)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_2906a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_2906a_level0_col0\" class=\"col_heading level0 col0\" >changeType</th>\n",
       "      <th id=\"T_2906a_level0_col1\" class=\"col_heading level0 col1\" >s3Path</th>\n",
       "      <th id=\"T_2906a_level0_col2\" class=\"col_heading level0 col2\" >dbPath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_2906a_row0_col0\" class=\"data row0 col0\" >PUT</td>\n",
       "      <td id=\"T_2906a_row0_col1\" class=\"data row0 col1\" >s3://kdb-demo-829845998889-kms/data/TorQ-Amazon-FinSpace-Starter-Pack/hdb/2014.04.21/</td>\n",
       "      <td id=\"T_2906a_row0_col2\" class=\"data row0 col2\" >/2014.04.21/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2906a_row1_col0\" class=\"data row1 col0\" >PUT</td>\n",
       "      <td id=\"T_2906a_row1_col1\" class=\"data row1 col1\" >s3://kdb-demo-829845998889-kms/data/TorQ-Amazon-FinSpace-Starter-Pack/hdb/2014.04.22/</td>\n",
       "      <td id=\"T_2906a_row1_col2\" class=\"data row1 col2\" >/2014.04.22/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2906a_row2_col0\" class=\"data row2 col0\" >PUT</td>\n",
       "      <td id=\"T_2906a_row2_col1\" class=\"data row2 col1\" >s3://kdb-demo-829845998889-kms/data/TorQ-Amazon-FinSpace-Starter-Pack/hdb/2014.04.23/</td>\n",
       "      <td id=\"T_2906a_row2_col2\" class=\"data row2 col2\" >/2014.04.23/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_2906a_row3_col0\" class=\"data row3 col0\" >PUT</td>\n",
       "      <td id=\"T_2906a_row3_col1\" class=\"data row3 col1\" >s3://kdb-demo-829845998889-kms/data/TorQ-Amazon-FinSpace-Starter-Pack/hdb/sym</td>\n",
       "      <td id=\"T_2906a_row3_col2\" class=\"data row3 col2\" >/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb49b0021f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "note_str = \"\"\n",
    "\n",
    "c_set_list = list_kx_changesets(client, environmentId=ENV_ID, databaseName=DB_NAME)\n",
    "\n",
    "if len(c_set_list) == 0:\n",
    "    note_str = \"<<Could not get changesets>>\"\n",
    "    \n",
    "print(100*\"=\")\n",
    "print(f\"Database: {DB_NAME}, Changesets: {len(c_set_list)} {note_str}\")\n",
    "print(100*\"=\")\n",
    "\n",
    "# sort by create time\n",
    "c_set_list = sorted(c_set_list, key=lambda d: d['createdTimestamp']) \n",
    "\n",
    "for c in c_set_list:\n",
    "    c_set_id = c['changesetId']\n",
    "    print(f\"  Changeset: {c_set_id}: Created: {c['createdTimestamp']} ({c['status']})\")\n",
    "    c_rqs = client.get_kx_changeset(environmentId=ENV_ID, databaseName=DB_NAME, changesetId=c_set_id)['changeRequests']\n",
    "\n",
    "    chs_pdf = pd.DataFrame.from_dict(c_rqs).style.hide(axis='index')\n",
    "    display(chs_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dae0232-3666-491f-8891-dae30e12c9d8",
   "metadata": {},
   "source": [
    "# Create Scaling Group\n",
    "The scaling group represents the total compute avilable to the application. All clusters will be placed into the scaling group ans share the compute and memory of the scaling group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "613be7f8-fb82-4415-b30c-186ed470dba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = client.create_kx_scaling_group(\n",
    "    environmentId = ENV_ID, \n",
    "    scalingGroupName = SCALING_GROUP_NAME,\n",
    "    hostType=NODE_TYPE,\n",
    "    availabilityZoneId = AZ_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cab8d287-4c24-4e53-8dbd-642c73c7faf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'b2173643-c051-4523-8210-273cc930cb07',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/json',\n",
       "   'content-length': '238',\n",
       "   'connection': 'keep-alive',\n",
       "   'date': 'Fri, 01 Mar 2024 20:41:13 GMT',\n",
       "   'x-amzn-requestid': 'b2173643-c051-4523-8210-273cc930cb07',\n",
       "   'x-amz-apigw-id': 'T96IHFE9IAMEDpQ=',\n",
       "   'x-amzn-trace-id': 'Root=1-65e23d66-12aa9d7426890a6b3ac887ca',\n",
       "   'x-cache': 'Miss from cloudfront',\n",
       "   'via': '1.1 2b74e5ee4d30afba8f9df9907896c5f4.cloudfront.net (CloudFront)',\n",
       "   'x-amz-cf-pop': 'IAD50-C2',\n",
       "   'x-amz-cf-id': 'BThjfUsT4JOkuKzoopRon8SEWJ-d3U5DSVQxXwlqqWTUNnH0xBABfw=='},\n",
       "  'RetryAttempts': 0},\n",
       " 'environmentId': 'jlcenjvtkgzrdek2qqv7ic',\n",
       " 'scalingGroupName': 'SCALING_GROUP_torq',\n",
       " 'hostType': 'kx.sg.4xlarge',\n",
       " 'availabilityZoneId': 'use1-az6',\n",
       " 'status': 'CREATING',\n",
       " 'lastModifiedTimestamp': datetime.datetime(2024, 3, 1, 20, 41, 12, 572000, tzinfo=tzlocal()),\n",
       " 'createdTimestamp': datetime.datetime(2024, 3, 1, 20, 41, 12, 503000, tzinfo=tzlocal())}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6943fb16-8989-4199-a0fd-5c7c0d5aa56e",
   "metadata": {},
   "source": [
    "# Create Shared Volume\n",
    "The shared volume is a common storage device for the application. Every cluster using the shared volume will have a writable directory named after the cluster, can read the directories named after other clusters in the application using the volume. Also, there is a common "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4a8a247-d029-4f9b-aaf5-c6e2ffe200a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = client.create_kx_volume(\n",
    "    environmentId = ENV_ID, \n",
    "    volumeType = 'NAS_1',\n",
    "    volumeName = VOLUME_NAME,\n",
    "    description = 'Shared volume between TP and RDB',\n",
    "    nas1Configuration = NAS1_CONFIG,\n",
    "    azMode='SINGLE',\n",
    "    availabilityZoneIds=[ AZ_ID ]    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ec4876f-5ecc-420e-aff8-9c88c8c9deb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'c66b4ed3-5c1b-41d0-9202-a0dbcfc9fb05',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/json',\n",
       "   'content-length': '431',\n",
       "   'connection': 'keep-alive',\n",
       "   'date': 'Fri, 01 Mar 2024 20:41:14 GMT',\n",
       "   'x-amzn-requestid': 'c66b4ed3-5c1b-41d0-9202-a0dbcfc9fb05',\n",
       "   'x-amz-apigw-id': 'T96IfFScIAMEYlw=',\n",
       "   'x-amzn-trace-id': 'Root=1-65e23d69-26856e8e31f80737480293f3',\n",
       "   'x-cache': 'Miss from cloudfront',\n",
       "   'via': '1.1 2b74e5ee4d30afba8f9df9907896c5f4.cloudfront.net (CloudFront)',\n",
       "   'x-amz-cf-pop': 'IAD50-C2',\n",
       "   'x-amz-cf-id': 'dvAlhFajzKW9f58ointAKgpTdNGcZDVxRYDaa25sHIHpGryPEs2fzA=='},\n",
       "  'RetryAttempts': 0},\n",
       " 'environmentId': 'jlcenjvtkgzrdek2qqv7ic',\n",
       " 'volumeName': 'SHARED_torq',\n",
       " 'volumeType': 'NAS_1',\n",
       " 'volumeArn': 'arn:aws:finspace:us-east-1:829845998889:kxEnvironment/jlcenjvtkgzrdek2qqv7ic/kxVolume/SHARED_torq',\n",
       " 'nas1Configuration': {'type': 'SSD_250', 'size': 1200},\n",
       " 'status': 'CREATING',\n",
       " 'azMode': 'SINGLE',\n",
       " 'description': 'Shared volume between TP and RDB',\n",
       " 'availabilityZoneIds': ['use1-az6'],\n",
       " 'createdTimestamp': datetime.datetime(2024, 3, 1, 20, 41, 14, 52000, tzinfo=tzlocal())}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e718537-8853-4f21-8cc7-36b489e380c4",
   "metadata": {},
   "source": [
    "# Wait for Volume and Scaling Group\n",
    "Before proceeding to use Volumes and Scaling groups, wait for their creation to complete.\n",
    "\n",
    "Volume will be used by the dataview.    \n",
    "Dataview and Scaling Group will be used by the clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3ed8931-e458-4ffb-83cc-0aa4da4d9f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling Group: SCALING_GROUP_torq status is CREATING, total wait 0:00:00, waiting 30 sec ...\n",
      "Scaling Group: SCALING_GROUP_torq status is CREATING, total wait 0:00:30, waiting 30 sec ...\n",
      "Scaling Group: SCALING_GROUP_torq status is CREATING, total wait 0:01:00, waiting 30 sec ...\n",
      "Scaling Group: SCALING_GROUP_torq status is CREATING, total wait 0:01:30, waiting 30 sec ...\n",
      "Scaling Group: SCALING_GROUP_torq status is CREATING, total wait 0:02:00, waiting 30 sec ...\n",
      "Scaling Group: SCALING_GROUP_torq status is CREATING, total wait 0:02:30, waiting 30 sec ...\n",
      "Scaling Group: SCALING_GROUP_torq status is CREATING, total wait 0:03:00, waiting 30 sec ...\n",
      "Scaling Group: SCALING_GROUP_torq status is CREATING, total wait 0:03:30, waiting 30 sec ...\n",
      "Scaling Group: SCALING_GROUP_torq status is CREATING, total wait 0:04:00, waiting 30 sec ...\n",
      "Scaling Group: SCALING_GROUP_torq status is CREATING, total wait 0:04:30, waiting 30 sec ...\n",
      "Scaling Group: SCALING_GROUP_torq status is now ACTIVE, total wait 0:05:00\n",
      "** DONE **\n",
      "Volume: SHARED_torq status is CREATING, total wait 0:00:00, waiting 30 sec ...\n",
      "Volume: SHARED_torq status is CREATING, total wait 0:00:30, waiting 30 sec ...\n",
      "Volume: SHARED_torq status is CREATING, total wait 0:01:00, waiting 30 sec ...\n",
      "Volume: SHARED_torq status is CREATING, total wait 0:01:30, waiting 30 sec ...\n",
      "Volume: SHARED_torq status is CREATING, total wait 0:02:00, waiting 30 sec ...\n",
      "Volume: SHARED_torq status is now ACTIVE, total wait 0:02:30\n",
      "** DONE **\n"
     ]
    }
   ],
   "source": [
    "# wait for the scaling group to create\n",
    "wait_for_scaling_group_status(client=client, environmentId=ENV_ID, scalingGroupName=SCALING_GROUP_NAME, show_wait=True)\n",
    "print(\"** DONE **\")\n",
    "\n",
    "# wait for the volume to create\n",
    "wait_for_volume_status(client=client, environmentId=ENV_ID, volumeName=VOLUME_NAME, show_wait=True)\n",
    "print(\"** DONE **\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe41eaeb-9c8e-44d3-b8bc-f354142f9140",
   "metadata": {},
   "source": [
    "# Create Dataview\n",
    "Create a dataview, for a specific (static) version of the database and have all of its data cached using the shared volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03434316-4ccc-420d-adee-715e6eb1bcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by create time\n",
    "c_set_list = sorted(c_set_list, key=lambda d: d['createdTimestamp']) \n",
    "\n",
    "resp = client.create_kx_dataview(\n",
    "    environmentId = ENV_ID, \n",
    "    databaseName=DB_NAME, \n",
    "    dataviewName=DBVIEW_NAME,\n",
    "    azMode='SINGLE',\n",
    "    availabilityZoneId=AZ_ID,\n",
    "    changesetId=c_set_list[-1]['changesetId'],\n",
    "    segmentConfigurations=[\n",
    "        { \n",
    "            'dbPaths': ['/*'],\n",
    "            'volumeName': VOLUME_NAME\n",
    "        }\n",
    "    ],\n",
    "    autoUpdate=False,\n",
    "    description = f'Dataview of database'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "734ab7da-ef78-4701-9a58-1eeacbd9c557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataview: finspace-database_DBVIEW status is CREATING, total wait 0:00:00, waiting 30 sec ...\n",
      "Dataview: finspace-database_DBVIEW status is CREATING, total wait 0:00:30, waiting 30 sec ...\n",
      "Dataview: finspace-database_DBVIEW status is CREATING, total wait 0:01:00, waiting 30 sec ...\n",
      "Dataview: finspace-database_DBVIEW status is CREATING, total wait 0:01:30, waiting 30 sec ...\n",
      "Dataview: finspace-database_DBVIEW status is CREATING, total wait 0:02:00, waiting 30 sec ...\n",
      "Dataview: finspace-database_DBVIEW status is CREATING, total wait 0:02:30, waiting 30 sec ...\n",
      "Dataview: finspace-database_DBVIEW status is CREATING, total wait 0:03:00, waiting 30 sec ...\n",
      "Dataview: finspace-database_DBVIEW status is CREATING, total wait 0:03:30, waiting 30 sec ...\n",
      "Dataview: finspace-database_DBVIEW status is CREATING, total wait 0:04:00, waiting 30 sec ...\n",
      "Dataview: finspace-database_DBVIEW status is CREATING, total wait 0:04:30, waiting 30 sec ...\n",
      "Dataview: finspace-database_DBVIEW status is CREATING, total wait 0:05:00, waiting 30 sec ...\n",
      "Dataview: finspace-database_DBVIEW status is CREATING, total wait 0:05:30, waiting 30 sec ...\n",
      "Dataview: finspace-database_DBVIEW status is now ACTIVE, total wait 0:06:00\n",
      "** DONE **\n"
     ]
    }
   ],
   "source": [
    "# wait for the view to create\n",
    "wait_for_dataview_status(client=client, environmentId=ENV_ID, databaseName=DB_NAME, dataviewName=DBVIEW_NAME, show_wait=True)\n",
    "print(\"** DONE **\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea431b0-c501-46bb-b72a-a5eb80a335b0",
   "metadata": {},
   "source": [
    "# Create Clusters\n",
    "With foundation resources now completed, create the needed clusters for the application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0c06ab-4dcb-4cc6-abc9-2c77ff3a4242",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stage Code to S3\n",
    "Code to be used in this application must be staged to an S3 bucket the service can read from, that code will then be deployed to the clusters as part of their creation workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b502a0a5-8610-4fc8-b6b7-04c47e89ba75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./torq_app.zip to s3://kdb-demo-829845998889-kms/code/torq_app.zip\n",
      "2023-06-05 21:25:21          0 \n",
      "2024-02-13 18:28:58      13775 basictick.zip\n",
      "2024-02-16 21:40:43        542 code.zip\n",
      "2023-12-21 19:47:37        574 codebundle.zip\n",
      "2024-02-02 21:34:56        582 codebundle1.zip\n",
      "2023-12-21 21:26:00        582 codebundle2.zip\n",
      "2023-11-22 14:58:53       1530 jpmc_code.zip\n",
      "2024-01-01 19:57:08      33781 kdb-tick-flat-largetable.zip\n",
      "2023-12-30 22:56:33      38867 kdb-tick-flat.zip\n",
      "2024-01-08 13:05:33      28741 kdb-tick.zip\n",
      "2023-08-22 16:58:18        765 qcode.zip\n",
      "2023-10-23 18:38:07       1390 taqcode.zip\n",
      "2024-03-01 20:54:56     483538 torq_app.zip\n",
      "2024-01-30 16:52:19       3583 tradeplus.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zip the code\n",
    "os.system(f\"zip -q -r {CODEBASE}.zip {TORQ_CODEBASE}/ {TORQ_FINSPACE_CODEBASE}/ -x '*.ipynb_checkpoints*' -x '*/hdb/*' -x '*.git*' -x '*/tests/*' -x '*/terraform-deployment/*' -x '*/docs/*' -x '*/lib/*' -x '*/html/*' -x '*/datadog/*'  -x '*/monit/*'\")\n",
    "\n",
    "# copy code to S3\n",
    "if AWS_ACCESS_KEY_ID is not None:\n",
    "    cp = f\"\"\"\n",
    "export AWS_ACCESS_KEY_ID={AWS_ACCESS_KEY_ID}\n",
    "export AWS_SECRET_ACCESS_KEY={AWS_SECRET_ACCESS_KEY}\n",
    "export AWS_SESSION_TOKEN={AWS_SESSION_TOKEN}\n",
    "\n",
    "aws s3 cp --exclude .DS_Store {CODEBASE}.zip s3://{S3_BUCKET}/code/{CODEBASE}.zip\n",
    "aws s3 ls s3://{S3_BUCKET}/code/\n",
    "\"\"\"\n",
    "else:\n",
    "    cp = f\"\"\"\n",
    "aws s3 cp --exclude .DS_Store {CODEBASE}.zip s3://{S3_BUCKET}/code/{CODEBASE}.zip\n",
    "aws s3 ls s3://{S3_BUCKET}/code/\n",
    "\"\"\"\n",
    "    \n",
    "# execute the S3 copy\n",
    "os.system(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0a75d53-e567-4a2d-b47b-170829d79f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating: discovery\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'f61c5e7b-7206-4bca-aeda-61f5c80f4391',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/json',\n",
       "   'content-length': '1672',\n",
       "   'connection': 'keep-alive',\n",
       "   'date': 'Fri, 01 Mar 2024 20:54:59 GMT',\n",
       "   'x-amzn-requestid': 'f61c5e7b-7206-4bca-aeda-61f5c80f4391',\n",
       "   'x-amz-apigw-id': 'T98JDFUboAMEchQ=',\n",
       "   'x-amzn-trace-id': 'Root=1-65e240a0-1ff460c97560ea35176ee0b7',\n",
       "   'x-cache': 'Miss from cloudfront',\n",
       "   'via': '1.1 2b74e5ee4d30afba8f9df9907896c5f4.cloudfront.net (CloudFront)',\n",
       "   'x-amz-cf-pop': 'IAD50-C2',\n",
       "   'x-amz-cf-id': '_uWpHfBtO6bxJ5MKHEEpGw-PETJN0738qaVZ1QDnjncvmgzhPTmLpA=='},\n",
       "  'RetryAttempts': 0},\n",
       " 'status': 'PENDING',\n",
       " 'clusterName': 'discovery',\n",
       " 'clusterType': 'GP',\n",
       " 'volumes': [{'volumeName': 'SHARED_torq', 'volumeType': 'NAS_1'}],\n",
       " 'databases': [{'databaseName': 'finspace-database',\n",
       "   'cacheConfigurations': [],\n",
       "   'dataviewConfiguration': {'dataviewName': 'finspace-database_DBVIEW',\n",
       "    'dataviewVersionId': 'Wsb9428zuiUV0OT7XKNqIA',\n",
       "    'changesetId': '9sb939X2p1mpLa97bptOTg',\n",
       "    'segmentConfigurations': [{'dbPaths': ['/*'],\n",
       "      'volumeName': 'SHARED_torq'}]}}],\n",
       " 'clusterDescription': 'Created with create_all notebook',\n",
       " 'releaseLabel': '1.0',\n",
       " 'vpcConfiguration': {'vpcId': 'vpc-0fe2b9c50f3ad382f',\n",
       "  'securityGroupIds': ['sg-0c99f1cfb9c3c7fd9'],\n",
       "  'subnetIds': ['subnet-04052219ec25b062b'],\n",
       "  'ipAddressType': 'IP_V4'},\n",
       " 'initializationScript': 'TorQ-Amazon-FinSpace-Starter-Pack/finspace_torq.q',\n",
       " 'commandLineArguments': [{'key': 'proctype', 'value': 'discovery'},\n",
       "  {'key': 'procname', 'value': 'discovery1'},\n",
       "  {'key': 'jsonlogs', 'value': 'true'},\n",
       "  {'key': 'noredirect', 'value': 'true'},\n",
       "  {'key': 's', 'value': '2'}],\n",
       " 'code': {'s3Bucket': 'kdb-demo-829845998889-kms',\n",
       "  's3Key': 'code/torq_app.zip'},\n",
       " 'executionRole': 'arn:aws:iam::829845998889:role/kdb-all-user',\n",
       " 'lastModifiedTimestamp': datetime.datetime(2024, 3, 1, 20, 54, 59, 400000, tzinfo=tzlocal()),\n",
       " 'savedownStorageConfiguration': {'volumeName': 'SHARED_torq'},\n",
       " 'azMode': 'SINGLE',\n",
       " 'availabilityZoneId': 'use1-az6',\n",
       " 'createdTimestamp': datetime.datetime(2024, 3, 1, 20, 54, 59, 373000, tzinfo=tzlocal()),\n",
       " 'scalingGroupConfiguration': {'scalingGroupName': 'SCALING_GROUP_torq',\n",
       "  'memoryReservation': 6,\n",
       "  'nodeCount': 1}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating: rdb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'e6148851-ea0b-4da2-b620-cfc5a93af3da',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/json',\n",
       "   'content-length': '1655',\n",
       "   'connection': 'keep-alive',\n",
       "   'date': 'Fri, 01 Mar 2024 20:55:02 GMT',\n",
       "   'x-amzn-requestid': 'e6148851-ea0b-4da2-b620-cfc5a93af3da',\n",
       "   'x-amz-apigw-id': 'T98JqE-8oAMEGVQ=',\n",
       "   'x-amzn-trace-id': 'Root=1-65e240a3-097124983f0126f408b89fb9',\n",
       "   'x-cache': 'Miss from cloudfront',\n",
       "   'via': '1.1 2b74e5ee4d30afba8f9df9907896c5f4.cloudfront.net (CloudFront)',\n",
       "   'x-amz-cf-pop': 'IAD50-C2',\n",
       "   'x-amz-cf-id': 'lj2jd_Tr7f_LfOCNULtMpl7-ITnzm_z33bVx9dyzgS1SMH1BpD6MAg=='},\n",
       "  'RetryAttempts': 0},\n",
       " 'status': 'PENDING',\n",
       " 'clusterName': 'rdb',\n",
       " 'clusterType': 'GP',\n",
       " 'volumes': [{'volumeName': 'SHARED_torq', 'volumeType': 'NAS_1'}],\n",
       " 'databases': [{'databaseName': 'finspace-database',\n",
       "   'cacheConfigurations': [],\n",
       "   'dataviewConfiguration': {'dataviewName': 'finspace-database_DBVIEW',\n",
       "    'dataviewVersionId': 'Wsb9428zuiUV0OT7XKNqIA',\n",
       "    'changesetId': '9sb939X2p1mpLa97bptOTg',\n",
       "    'segmentConfigurations': [{'dbPaths': ['/*'],\n",
       "      'volumeName': 'SHARED_torq'}]}}],\n",
       " 'clusterDescription': 'Created with create_all notebook',\n",
       " 'releaseLabel': '1.0',\n",
       " 'vpcConfiguration': {'vpcId': 'vpc-0fe2b9c50f3ad382f',\n",
       "  'securityGroupIds': ['sg-0c99f1cfb9c3c7fd9'],\n",
       "  'subnetIds': ['subnet-04052219ec25b062b'],\n",
       "  'ipAddressType': 'IP_V4'},\n",
       " 'initializationScript': 'TorQ-Amazon-FinSpace-Starter-Pack/finspace_torq.q',\n",
       " 'commandLineArguments': [{'key': 'proctype', 'value': 'rdb'},\n",
       "  {'key': 'procname', 'value': 'rdb1'},\n",
       "  {'key': 'jsonlogs', 'value': 'true'},\n",
       "  {'key': 'noredirect', 'value': 'true'},\n",
       "  {'key': 's', 'value': '2'}],\n",
       " 'code': {'s3Bucket': 'kdb-demo-829845998889-kms',\n",
       "  's3Key': 'code/torq_app.zip'},\n",
       " 'executionRole': 'arn:aws:iam::829845998889:role/kdb-all-user',\n",
       " 'lastModifiedTimestamp': datetime.datetime(2024, 3, 1, 20, 55, 2, 419000, tzinfo=tzlocal()),\n",
       " 'savedownStorageConfiguration': {'volumeName': 'SHARED_torq'},\n",
       " 'azMode': 'SINGLE',\n",
       " 'availabilityZoneId': 'use1-az6',\n",
       " 'createdTimestamp': datetime.datetime(2024, 3, 1, 20, 55, 2, 410000, tzinfo=tzlocal()),\n",
       " 'scalingGroupConfiguration': {'scalingGroupName': 'SCALING_GROUP_torq',\n",
       "  'memoryReservation': 6,\n",
       "  'nodeCount': 1}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating: hdb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'd9817bce-4290-4a9a-90e0-742da241d031',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/json',\n",
       "   'content-length': '1655',\n",
       "   'connection': 'keep-alive',\n",
       "   'date': 'Fri, 01 Mar 2024 20:55:05 GMT',\n",
       "   'x-amzn-requestid': 'd9817bce-4290-4a9a-90e0-742da241d031',\n",
       "   'x-amz-apigw-id': 'T98KHG2WoAMEGRw=',\n",
       "   'x-amzn-trace-id': 'Root=1-65e240a6-5d0c1076518493f904efad68',\n",
       "   'x-cache': 'Miss from cloudfront',\n",
       "   'via': '1.1 2b74e5ee4d30afba8f9df9907896c5f4.cloudfront.net (CloudFront)',\n",
       "   'x-amz-cf-pop': 'IAD50-C2',\n",
       "   'x-amz-cf-id': '3z8Mq4Fz87l0KhLAvXjJ0x4hD5ENBbTqx6PooKqGfU80rKyIAt2UPw=='},\n",
       "  'RetryAttempts': 0},\n",
       " 'status': 'PENDING',\n",
       " 'clusterName': 'hdb',\n",
       " 'clusterType': 'GP',\n",
       " 'volumes': [{'volumeName': 'SHARED_torq', 'volumeType': 'NAS_1'}],\n",
       " 'databases': [{'databaseName': 'finspace-database',\n",
       "   'cacheConfigurations': [],\n",
       "   'dataviewConfiguration': {'dataviewName': 'finspace-database_DBVIEW',\n",
       "    'dataviewVersionId': 'Wsb9428zuiUV0OT7XKNqIA',\n",
       "    'changesetId': '9sb939X2p1mpLa97bptOTg',\n",
       "    'segmentConfigurations': [{'dbPaths': ['/*'],\n",
       "      'volumeName': 'SHARED_torq'}]}}],\n",
       " 'clusterDescription': 'Created with create_all notebook',\n",
       " 'releaseLabel': '1.0',\n",
       " 'vpcConfiguration': {'vpcId': 'vpc-0fe2b9c50f3ad382f',\n",
       "  'securityGroupIds': ['sg-0c99f1cfb9c3c7fd9'],\n",
       "  'subnetIds': ['subnet-04052219ec25b062b'],\n",
       "  'ipAddressType': 'IP_V4'},\n",
       " 'initializationScript': 'TorQ-Amazon-FinSpace-Starter-Pack/finspace_torq.q',\n",
       " 'commandLineArguments': [{'key': 'proctype', 'value': 'hdb'},\n",
       "  {'key': 'procname', 'value': 'hdb1'},\n",
       "  {'key': 'jsonlogs', 'value': 'true'},\n",
       "  {'key': 'noredirect', 'value': 'true'},\n",
       "  {'key': 's', 'value': '4'}],\n",
       " 'code': {'s3Bucket': 'kdb-demo-829845998889-kms',\n",
       "  's3Key': 'code/torq_app.zip'},\n",
       " 'executionRole': 'arn:aws:iam::829845998889:role/kdb-all-user',\n",
       " 'lastModifiedTimestamp': datetime.datetime(2024, 3, 1, 20, 55, 5, 468000, tzinfo=tzlocal()),\n",
       " 'savedownStorageConfiguration': {'volumeName': 'SHARED_torq'},\n",
       " 'azMode': 'SINGLE',\n",
       " 'availabilityZoneId': 'use1-az6',\n",
       " 'createdTimestamp': datetime.datetime(2024, 3, 1, 20, 55, 5, 460000, tzinfo=tzlocal()),\n",
       " 'scalingGroupConfiguration': {'scalingGroupName': 'SCALING_GROUP_torq',\n",
       "  'memoryReservation': 6,\n",
       "  'nodeCount': 1}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: discovery status is PENDING, total wait 0:00:00, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:00:30, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:01:00, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:01:30, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:02:00, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:02:30, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:03:00, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:03:30, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:04:00, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:04:30, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:05:00, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:05:30, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:06:00, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:06:30, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:07:00, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:07:30, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:08:00, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:08:30, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:09:00, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:09:30, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:10:00, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:10:30, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:11:00, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:11:30, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:12:00, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:12:30, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:13:00, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:13:30, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:14:00, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:14:30, waiting 30 sec ...\n",
      "Cluster: discovery status is CREATING, total wait 0:15:00, waiting 30 sec ...\n",
      "Cluster: discovery status is now RUNNING, total wait 0:15:30\n",
      "Cluster: rdb status is CREATING, total wait 0:00:00, waiting 30 sec ...\n",
      "Cluster: rdb status is now RUNNING, total wait 0:00:30\n",
      "Creating: gateway\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'f687caeb-446e-4648-b6f3-06b5a99f1e2b',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/json',\n",
       "   'content-length': '1667',\n",
       "   'connection': 'keep-alive',\n",
       "   'date': 'Fri, 01 Mar 2024 21:11:17 GMT',\n",
       "   'x-amzn-requestid': 'f687caeb-446e-4648-b6f3-06b5a99f1e2b',\n",
       "   'x-amz-apigw-id': 'T9-h4GWWIAMEbzA=',\n",
       "   'x-amzn-trace-id': 'Root=1-65e24472-2a69d5d52351904227ec37ba',\n",
       "   'x-cache': 'Miss from cloudfront',\n",
       "   'via': '1.1 2b74e5ee4d30afba8f9df9907896c5f4.cloudfront.net (CloudFront)',\n",
       "   'x-amz-cf-pop': 'IAD50-C2',\n",
       "   'x-amz-cf-id': 'mJ5HpEYmVBe91MhEhETJbvt3w44B_QaVOzX2FJuPfLO6M1jvvT6PHg=='},\n",
       "  'RetryAttempts': 0},\n",
       " 'status': 'PENDING',\n",
       " 'clusterName': 'gateway',\n",
       " 'clusterType': 'GP',\n",
       " 'volumes': [{'volumeName': 'SHARED_torq', 'volumeType': 'NAS_1'}],\n",
       " 'databases': [{'databaseName': 'finspace-database',\n",
       "   'cacheConfigurations': [],\n",
       "   'dataviewConfiguration': {'dataviewName': 'finspace-database_DBVIEW',\n",
       "    'dataviewVersionId': 'Wsb9428zuiUV0OT7XKNqIA',\n",
       "    'changesetId': '9sb939X2p1mpLa97bptOTg',\n",
       "    'segmentConfigurations': [{'dbPaths': ['/*'],\n",
       "      'volumeName': 'SHARED_torq'}]}}],\n",
       " 'clusterDescription': 'Created with create_all notebook',\n",
       " 'releaseLabel': '1.0',\n",
       " 'vpcConfiguration': {'vpcId': 'vpc-0fe2b9c50f3ad382f',\n",
       "  'securityGroupIds': ['sg-0c99f1cfb9c3c7fd9'],\n",
       "  'subnetIds': ['subnet-04052219ec25b062b'],\n",
       "  'ipAddressType': 'IP_V4'},\n",
       " 'initializationScript': 'TorQ-Amazon-FinSpace-Starter-Pack/finspace_torq.q',\n",
       " 'commandLineArguments': [{'key': 'proctype', 'value': 'gateway'},\n",
       "  {'key': 'procname', 'value': 'gateway1'},\n",
       "  {'key': 'jsonlogs', 'value': 'true'},\n",
       "  {'key': 'noredirect', 'value': 'true'},\n",
       "  {'key': 's', 'value': '2'}],\n",
       " 'code': {'s3Bucket': 'kdb-demo-829845998889-kms',\n",
       "  's3Key': 'code/torq_app.zip'},\n",
       " 'executionRole': 'arn:aws:iam::829845998889:role/kdb-all-user',\n",
       " 'lastModifiedTimestamp': datetime.datetime(2024, 3, 1, 21, 11, 17, 320000, tzinfo=tzlocal()),\n",
       " 'savedownStorageConfiguration': {'volumeName': 'SHARED_torq'},\n",
       " 'azMode': 'SINGLE',\n",
       " 'availabilityZoneId': 'use1-az6',\n",
       " 'createdTimestamp': datetime.datetime(2024, 3, 1, 21, 11, 17, 301000, tzinfo=tzlocal()),\n",
       " 'scalingGroupConfiguration': {'scalingGroupName': 'SCALING_GROUP_torq',\n",
       "  'memoryReservation': 6,\n",
       "  'nodeCount': 1}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating: feed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '0385423e-58da-47ab-bb99-27274c05a3de',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/json',\n",
       "   'content-length': '1669',\n",
       "   'connection': 'keep-alive',\n",
       "   'date': 'Fri, 01 Mar 2024 21:11:20 GMT',\n",
       "   'x-amzn-requestid': '0385423e-58da-47ab-bb99-27274c05a3de',\n",
       "   'x-amz-apigw-id': 'T9-icFLXoAMEnXg=',\n",
       "   'x-amzn-trace-id': 'Root=1-65e24475-1501cb68413705f977c81a23',\n",
       "   'x-cache': 'Miss from cloudfront',\n",
       "   'via': '1.1 2b74e5ee4d30afba8f9df9907896c5f4.cloudfront.net (CloudFront)',\n",
       "   'x-amz-cf-pop': 'IAD50-C2',\n",
       "   'x-amz-cf-id': 'DmJRlxP2ZaXzfnzzcriVgHfjDTJf4x6TR9Ia7ZOFW4R51ucNJHXb-w=='},\n",
       "  'RetryAttempts': 0},\n",
       " 'status': 'PENDING',\n",
       " 'clusterName': 'feed',\n",
       " 'clusterType': 'GP',\n",
       " 'volumes': [{'volumeName': 'SHARED_torq', 'volumeType': 'NAS_1'}],\n",
       " 'databases': [{'databaseName': 'finspace-database',\n",
       "   'cacheConfigurations': [],\n",
       "   'dataviewConfiguration': {'dataviewName': 'finspace-database_DBVIEW',\n",
       "    'dataviewVersionId': 'Wsb9428zuiUV0OT7XKNqIA',\n",
       "    'changesetId': '9sb939X2p1mpLa97bptOTg',\n",
       "    'segmentConfigurations': [{'dbPaths': ['/*'],\n",
       "      'volumeName': 'SHARED_torq'}]}}],\n",
       " 'clusterDescription': 'Created with create_all notebook',\n",
       " 'releaseLabel': '1.0',\n",
       " 'vpcConfiguration': {'vpcId': 'vpc-0fe2b9c50f3ad382f',\n",
       "  'securityGroupIds': ['sg-0c99f1cfb9c3c7fd9'],\n",
       "  'subnetIds': ['subnet-04052219ec25b062b'],\n",
       "  'ipAddressType': 'IP_V4'},\n",
       " 'initializationScript': 'TorQ-Amazon-FinSpace-Starter-Pack/finspace_torq.q',\n",
       " 'commandLineArguments': [{'key': 'proctype', 'value': 'tradeFeed'},\n",
       "  {'key': 'procname', 'value': 'tradeFeed1'},\n",
       "  {'key': 'jsonlogs', 'value': 'true'},\n",
       "  {'key': 'noredirect', 'value': 'true'},\n",
       "  {'key': 's', 'value': '2'}],\n",
       " 'code': {'s3Bucket': 'kdb-demo-829845998889-kms',\n",
       "  's3Key': 'code/torq_app.zip'},\n",
       " 'executionRole': 'arn:aws:iam::829845998889:role/kdb-all-user',\n",
       " 'lastModifiedTimestamp': datetime.datetime(2024, 3, 1, 21, 11, 20, 378000, tzinfo=tzlocal()),\n",
       " 'savedownStorageConfiguration': {'volumeName': 'SHARED_torq'},\n",
       " 'azMode': 'SINGLE',\n",
       " 'availabilityZoneId': 'use1-az6',\n",
       " 'createdTimestamp': datetime.datetime(2024, 3, 1, 21, 11, 20, 369000, tzinfo=tzlocal()),\n",
       " 'scalingGroupConfiguration': {'scalingGroupName': 'SCALING_GROUP_torq',\n",
       "  'memoryReservation': 6,\n",
       "  'nodeCount': 1}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for c in clusters:\n",
    "    \n",
    "    # wait for a cluster?\n",
    "    if c['type'] == \"WAIT\":\n",
    "        wait_for_cluster_status(client, environmentId=ENV_ID, clusterName=c['name'], show_wait=True)\n",
    "        continue\n",
    "    \n",
    "    cluster_name = c['name']\n",
    "    cluster_type = c['type']\n",
    "    cluster_init = c['init']\n",
    "    cluster_args = c['args']\n",
    "    \n",
    "    # cluster already exists\n",
    "    resp = get_kx_cluster(client, environmentId=ENV_ID, clusterName=cluster_name)\n",
    "    if resp is not None:\n",
    "        print(f\"Cluster: {cluster_name} already exists\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Creating: {cluster_name}\")\n",
    "    \n",
    "    resp = client.create_kx_cluster(\n",
    "        environmentId=ENV_ID, \n",
    "        clusterName=cluster_name,\n",
    "        clusterType=cluster_type,\n",
    "        releaseLabel = '1.0',\n",
    "        executionRole=EXECUTION_ROLE,\n",
    "        databases=DATABASE_CONFIG,\n",
    "        scalingGroupConfiguration={\n",
    "            'memoryReservation': 6,\n",
    "            'nodeCount': 1,\n",
    "            'scalingGroupName': SCALING_GROUP_NAME,\n",
    "        },\n",
    "        savedownStorageConfiguration ={ 'volumeName': VOLUME_NAME },\n",
    "#        tickerplantLogConfiguration ={ 'tickerplantLogVolumes': [ VOLUME_NAME ] },\n",
    "        clusterDescription=\"Created with create_all notebook\",\n",
    "        code=CODE_CONFIG,\n",
    "        initializationScript=cluster_init,\n",
    "        commandLineArguments=cluster_args,\n",
    "        azMode=AZ_MODE,\n",
    "        availabilityZoneId=AZ_ID,\n",
    "        vpcConfiguration={ \n",
    "            'vpcId': VPC_ID,\n",
    "            'securityGroupIds': SECURITY_GROUPS,\n",
    "            'subnetIds': SUBNET_IDS,\n",
    "            'ipAddressType': 'IP_V4' }\n",
    "    )\n",
    "    \n",
    "    display(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8491391-8c01-4190-a2bd-23fa888bf781",
   "metadata": {},
   "source": [
    "## Wait for all clusters to finish creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0946ca26-c4b0-410d-ade5-18a47bf2318a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: discovery status is now RUNNING, total wait 0:00:00\n",
      "Cluster: rdb status is now RUNNING, total wait 0:00:00\n",
      "Cluster: hdb status is now RUNNING, total wait 0:00:00\n",
      "Cluster: discovery status is now RUNNING, total wait 0:00:00\n",
      "Cluster: rdb status is now RUNNING, total wait 0:00:00\n",
      "Cluster: gateway status is PENDING, total wait 0:00:00, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:00:30, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:01:00, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:01:30, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:02:00, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:02:30, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:03:00, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:03:30, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:04:00, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:04:30, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:05:00, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:05:30, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:06:00, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:06:30, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:07:00, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:07:30, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:08:00, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:08:30, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:09:00, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:09:30, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:10:00, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:10:30, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:11:00, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:11:30, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:12:00, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:12:30, waiting 30 sec ...\n",
      "Cluster: gateway status is CREATING, total wait 0:13:00, waiting 30 sec ...\n",
      "Cluster: gateway status is now RUNNING, total wait 0:13:30\n",
      "Cluster: feed status is now RUNNING, total wait 0:00:00\n",
      "** ALL DONE **\n"
     ]
    }
   ],
   "source": [
    "# Wait for all clusters to start\n",
    "for c in clusters:\n",
    "    cluster_name = c['name']\n",
    "    wait_for_cluster_status(client, environmentId=ENV_ID, clusterName=cluster_name, show_wait=True)\n",
    "\n",
    "print(\"** ALL DONE **\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230207e8-c297-4d7e-af65-4396fa5b4deb",
   "metadata": {},
   "source": [
    "# List Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c50c578-05e8-49e7-8deb-1f6b94b10221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clusterName</th>\n",
       "      <th>status</th>\n",
       "      <th>clusterType</th>\n",
       "      <th>capacityConfiguration</th>\n",
       "      <th>commandLineArguments</th>\n",
       "      <th>clusterDescription</th>\n",
       "      <th>lastModifiedTimestamp</th>\n",
       "      <th>createdTimestamp</th>\n",
       "      <th>databaseName</th>\n",
       "      <th>cacheConfigurations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>discovery</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>GP</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'key': 'proctype', 'value': 'discovery'}, {'key': 'procname', 'value': 'discovery1'}, {'key': 'jsonlogs', 'value': 'true'}, {'key': 'noredirect', 'value': 'true'}, {'key': 's', 'value': '2'}]</td>\n",
       "      <td>Created with create_all notebook</td>\n",
       "      <td>2024-03-01 21:10:34.715000+00:00</td>\n",
       "      <td>2024-03-01 20:54:59.373000+00:00</td>\n",
       "      <td>finspace-database</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feed</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>GP</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'key': 'proctype', 'value': 'tradeFeed'}, {'key': 'procname', 'value': 'tradeFeed1'}, {'key': 'jsonlogs', 'value': 'true'}, {'key': 'noredirect', 'value': 'true'}, {'key': 's', 'value': '2'}]</td>\n",
       "      <td>Created with create_all notebook</td>\n",
       "      <td>2024-03-01 21:24:50.829000+00:00</td>\n",
       "      <td>2024-03-01 21:11:20.369000+00:00</td>\n",
       "      <td>finspace-database</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gateway</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>GP</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'key': 'proctype', 'value': 'gateway'}, {'key': 'procname', 'value': 'gateway1'}, {'key': 'jsonlogs', 'value': 'true'}, {'key': 'noredirect', 'value': 'true'}, {'key': 's', 'value': '2'}]</td>\n",
       "      <td>Created with create_all notebook</td>\n",
       "      <td>2024-03-01 21:24:49.462000+00:00</td>\n",
       "      <td>2024-03-01 21:11:17.301000+00:00</td>\n",
       "      <td>finspace-database</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hdb</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>GP</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'key': 'proctype', 'value': 'hdb'}, {'key': 'procname', 'value': 'hdb1'}, {'key': 'jsonlogs', 'value': 'true'}, {'key': 'noredirect', 'value': 'true'}, {'key': 's', 'value': '4'}]</td>\n",
       "      <td>Created with create_all notebook</td>\n",
       "      <td>2024-03-01 21:10:44.925000+00:00</td>\n",
       "      <td>2024-03-01 20:55:05.460000+00:00</td>\n",
       "      <td>finspace-database</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rdb</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>GP</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'key': 'proctype', 'value': 'rdb'}, {'key': 'procname', 'value': 'rdb1'}, {'key': 'jsonlogs', 'value': 'true'}, {'key': 'noredirect', 'value': 'true'}, {'key': 's', 'value': '2'}]</td>\n",
       "      <td>Created with create_all notebook</td>\n",
       "      <td>2024-03-01 21:10:44.563000+00:00</td>\n",
       "      <td>2024-03-01 20:55:02.410000+00:00</td>\n",
       "      <td>finspace-database</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  clusterName   status clusterType capacityConfiguration  \\\n",
       "1   discovery  RUNNING          GP                  None   \n",
       "2        feed  RUNNING          GP                  None   \n",
       "3     gateway  RUNNING          GP                  None   \n",
       "4         hdb  RUNNING          GP                  None   \n",
       "5         rdb  RUNNING          GP                  None   \n",
       "\n",
       "                                                                                                                                                                                commandLineArguments  \\\n",
       "1  [{'key': 'proctype', 'value': 'discovery'}, {'key': 'procname', 'value': 'discovery1'}, {'key': 'jsonlogs', 'value': 'true'}, {'key': 'noredirect', 'value': 'true'}, {'key': 's', 'value': '2'}]   \n",
       "2  [{'key': 'proctype', 'value': 'tradeFeed'}, {'key': 'procname', 'value': 'tradeFeed1'}, {'key': 'jsonlogs', 'value': 'true'}, {'key': 'noredirect', 'value': 'true'}, {'key': 's', 'value': '2'}]   \n",
       "3      [{'key': 'proctype', 'value': 'gateway'}, {'key': 'procname', 'value': 'gateway1'}, {'key': 'jsonlogs', 'value': 'true'}, {'key': 'noredirect', 'value': 'true'}, {'key': 's', 'value': '2'}]   \n",
       "4              [{'key': 'proctype', 'value': 'hdb'}, {'key': 'procname', 'value': 'hdb1'}, {'key': 'jsonlogs', 'value': 'true'}, {'key': 'noredirect', 'value': 'true'}, {'key': 's', 'value': '4'}]   \n",
       "5              [{'key': 'proctype', 'value': 'rdb'}, {'key': 'procname', 'value': 'rdb1'}, {'key': 'jsonlogs', 'value': 'true'}, {'key': 'noredirect', 'value': 'true'}, {'key': 's', 'value': '2'}]   \n",
       "\n",
       "                 clusterDescription            lastModifiedTimestamp  \\\n",
       "1  Created with create_all notebook 2024-03-01 21:10:34.715000+00:00   \n",
       "2  Created with create_all notebook 2024-03-01 21:24:50.829000+00:00   \n",
       "3  Created with create_all notebook 2024-03-01 21:24:49.462000+00:00   \n",
       "4  Created with create_all notebook 2024-03-01 21:10:44.925000+00:00   \n",
       "5  Created with create_all notebook 2024-03-01 21:10:44.563000+00:00   \n",
       "\n",
       "                  createdTimestamp       databaseName  cacheConfigurations  \n",
       "1 2024-03-01 20:54:59.373000+00:00  finspace-database                  NaN  \n",
       "2 2024-03-01 21:11:20.369000+00:00  finspace-database                  NaN  \n",
       "3 2024-03-01 21:11:17.301000+00:00  finspace-database                  NaN  \n",
       "4 2024-03-01 20:55:05.460000+00:00  finspace-database                  NaN  \n",
       "5 2024-03-01 20:55:02.410000+00:00  finspace-database                  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cdf = get_clusters(client, environmentId=ENV_ID)\n",
    "\n",
    "all_clusters = [d['name'] for d in clusters if 'name' in d]\n",
    "\n",
    "if cdf is not None:\n",
    "    cdf = cdf[cdf['clusterName'].isin(all_clusters)]\n",
    "\n",
    "display(cdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e91a23b-b100-4763-9c50-c819f5824202",
   "metadata": {},
   "source": [
    "# All Processes Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86f33240-bb12-49f3-8d9c-5783c25eb182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Run: 2024-03-01 21:25:00.567560\n"
     ]
    }
   ],
   "source": [
    "print( f\"Last Run: {datetime.datetime.now()}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f05fa3-fbe0-443b-986e-428fb1ca4ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
