{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28bea13b-67bd-4a0e-8eab-3b8ffd37259e",
   "metadata": {},
   "source": [
    "# Welcome Notebook\n",
    "This notebook walks through the process of creating and populating your first database with FinSpace Managed KX.\n",
    "\n",
    "## Before you start\n",
    "Before you start this notebook, it is assumed you have the following:\n",
    "- FinSpace Managed KX environment created in AWS account\n",
    "- S3 staging bucket for data and code\n",
    "  - This notebook boto's profile and the Managed KX environment can access the bucket\n",
    "- Setup in ~/.aws directory\n",
    "  - config is set (json and region)\n",
    "  - default credentials are set (aws_access_key_id, aws_secret_access_key, aws_session_token)\n",
    "\n",
    "## Steps\n",
    "1. Untar hdb.tar.gz for the hdb data\n",
    "2. Upload hdb to staging S3 bucket\n",
    "3. Create database\n",
    "4. Add HDB data to database\n",
    "5. Create a Cluster\n",
    "6. Get the connectionString"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17a02c0-4f56-455c-a28a-dd102a88201c",
   "metadata": {},
   "source": [
    "## Setup\n",
    "imports, environmentId, accountId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9d543f3-1cd5-4a0e-8be7-a9eb0ac35878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "from managed_kx import *\n",
    "from env2 import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5265616-6aa4-4b7b-b038-8e26e71d19e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source data directory\n",
    "SOURCE_DATA_DIR=\"hdb\"\n",
    "\n",
    "# S3 bucket for external data and code\n",
    "S3_DEST=f\"s3://{S3_BUCKET}/data/{SOURCE_DATA_DIR}/\"\n",
    "CODEBASE=\"code\"\n",
    "CODE_PATH=f\"code/{CODEBASE}.zip\"\n",
    "\n",
    "# Managed KX Database and Cluster names to create\n",
    "DB_NAME=\"welcomedb\"\n",
    "DELETE_CLUSTER=False\n",
    "DELETE_DATABASE=False\n",
    "\n",
    "create_delete=True\n",
    "\n",
    "if create_delete:\n",
    "    DB_NAME=\"create_delete_db\"\n",
    "    DELETE_CLUSTER=True\n",
    "    DELETE_DATABASE=True\n",
    "    \n",
    "CLUSTER_NAME=f\"cluster_{DB_NAME}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e054ddd-3313-4ac3-b0b3-3c93b55e977e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using variables ...\n"
     ]
    }
   ],
   "source": [
    "# triggers credential get\n",
    "session=None\n",
    "\n",
    "try:\n",
    "    subprocess.call([\"which\", \"ada\"])\n",
    "    os.system(f\"ada credentials update --account={ACCOUNT_ID} --provider=isengard --role=Admin --once\")\n",
    "except: \n",
    "    None\n",
    "\n",
    "if AWS_ACCESS_KEY_ID is None:\n",
    "    print(\"Using Defaults ...\")\n",
    "    # create AWS session: using access variables\n",
    "    session = boto3.Session()\n",
    "else:\n",
    "    print(\"Using variables ...\")\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "        aws_session_token=AWS_SESSION_TOKEN\n",
    "    )\n",
    "\n",
    "# create finspace client\n",
    "client = session.client(service_name='finspace', endpoint_url=ENDPOINT_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849f954c-7cfa-4b29-be4f-0854aa7cbd06",
   "metadata": {},
   "source": [
    "# 0. Environment Check\n",
    "Be sure the infrastructure ID has been entitled to the bucket you will be staging the HDB to. The environment will also need access to the KMX key used when creating the environment.\n",
    "\n",
    "## Permission Templates\n",
    "\n",
    "### S3 Permission\n",
    "Example of code and data access to the same S3 bucket.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"finspace.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:PutObjectTagging\",\n",
    "                \"s3:PutObjectAcl\",\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:GetObjectVersion\",\n",
    "                \"s3:GetObjectTagging\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::S3_BUCKET/*\",\n",
    "                \"arn:aws:s3:::S3_BUCKET\"\n",
    "            ],\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"aws:SourceAccount\": \"ACCOUNT_ID\"\n",
    "                },\n",
    "                \"ArnEquals\": {\n",
    "                    \"aws:SourceArn\": \"arn:aws:finspace:us-east-1:ACCOUNT_ID:kxEnvironment/ENV_ID/*\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "### KMS Key\n",
    "Be sure the environment has access to use the KMS key given in environment creation.\n",
    "\n",
    "```\n",
    "\"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"Enable Managed kdb Insights Access\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"finspace.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"kms:Encrypt\",\n",
    "                \"kms:Decrypt\",\n",
    "                \"kms:GenerateDataKey\"\n",
    "            ],\n",
    "            \"Resource\": \"arn:aws:kms:us-east-1:ACCOUNT_ID:key/KEY_ID\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"aws:SourceAccount\": \"ACCOUNT_ID\"\n",
    "                },\n",
    "                \"ArnLike\": {\n",
    "                    \"aws:SourceArn\": \"arn:aws:finspace:us-east-1:ACCOUNT_ID:kxEnvironment/ENV_ID/*\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "   ]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d218119-1aa3-4485-a940-5dcde32b3fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment Information\n",
      "{\n",
      "    \"availabilityZoneIds\": [\n",
      "        \"use1-az6\",\n",
      "        \"use1-az4\",\n",
      "        \"use1-az1\"\n",
      "    ],\n",
      "    \"awsAccountId\": \"612841383594\",\n",
      "    \"certificateAuthorityArn\": \"arn:aws:acm-pca:us-east-1:952604696585:certificate-authority/0bd40a67-e61c-4e0f-8d83-9f84b10b4653\",\n",
      "    \"creationTimestamp\": \"2023-05-30T21:49:29.29Z\",\n",
      "    \"dedicatedServiceAccountId\": \"952604696585\",\n",
      "    \"description\": \"Anvironment created after last beta release ahead of GA\",\n",
      "    \"dnsStatus\": \"NONE\",\n",
      "    \"environmentArn\": \"arn:aws:finspace:us-east-1:612841383594:kxEnvironment/itcdoumzc5cixt5vh4t6dp\",\n",
      "    \"environmentId\": \"itcdoumzc5cixt5vh4t6dp\",\n",
      "    \"kmsKeyId\": \"arn:aws:kms:us-east-1:612841383594:key/bbfad1fa-9e38-47f1-986d-33fb976a9ec4\",\n",
      "    \"name\": \"Managed_KX_Beta_20230530\",\n",
      "    \"status\": \"CREATED\",\n",
      "    \"tgwStatus\": \"SUCCESSFULLY_UPDATED\",\n",
      "    \"transitGatewayConfiguration\": {\n",
      "        \"routableCIDRSpace\": \"100.64.0.0/26\",\n",
      "        \"transitGatewayID\": \"tgw-08a5795d33483b14f\"\n",
      "    },\n",
      "    \"updateTimestamp\": \"2023-05-30T23:30:49.49Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "resp=get_kx_environment(client, environmentId=ENV_ID)\n",
    "\n",
    "print(\"Environment Information\")\n",
    "print(json.dumps(resp,sort_keys=True,indent=4,default=str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc29d8fc-c234-4c65-a633-bb9e16d6a772",
   "metadata": {},
   "source": [
    "## 1. Untar hdb.tar.gz\n",
    "hdb database will be found in hdb directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "157b75f5-b582-490e-ae17-eb14eaafa21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf hdb.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fec4ecf-cba3-440f-a56e-4ec726c9f8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 52\n",
      "drwxr-xr-x. 12 ec2-user ec2-user 16384 Apr 24 23:17 .\n",
      "drwxr-xr-x.  7 ec2-user ec2-user 16384 May 31 14:59 ..\n",
      "drwxr-xr-x.  3 ec2-user ec2-user    21 Apr 24 23:17 2023.04.14\n",
      "drwxr-xr-x.  3 ec2-user ec2-user    21 Apr 24 23:17 2023.04.15\n",
      "drwxr-xr-x.  3 ec2-user ec2-user    21 Apr 24 23:17 2023.04.16\n",
      "drwxr-xr-x.  3 ec2-user ec2-user    21 Apr 24 23:17 2023.04.17\n",
      "drwxr-xr-x.  3 ec2-user ec2-user    21 Apr 24 23:17 2023.04.18\n",
      "drwxr-xr-x.  3 ec2-user ec2-user    21 Apr 24 23:17 2023.04.19\n",
      "drwxr-xr-x.  3 ec2-user ec2-user    21 Apr 24 23:17 2023.04.20\n",
      "drwxr-xr-x.  3 ec2-user ec2-user    21 Apr 24 23:17 2023.04.21\n",
      "drwxr-xr-x.  3 ec2-user ec2-user    21 Apr 24 23:17 2023.04.22\n",
      "drwxr-xr-x.  3 ec2-user ec2-user    21 Apr 24 23:17 2023.04.23\n",
      "-rw-r--r--.  1 ec2-user ec2-user 16392 Apr 24 23:17 sym\n"
     ]
    }
   ],
   "source": [
    "!ls -la hdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c8cbbe-654e-4385-92bc-5c7b80b5f0f3",
   "metadata": {},
   "source": [
    "# 2. Upload hdb data\n",
    "using aws cli, copy hdb to staging bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af169292-13fc-4b1b-863d-789d5a042d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE 2023.01.29/\n",
      "                           PRE 2023.01.30/\n",
      "                           PRE 2023.01.31/\n",
      "                           PRE 2023.02.01/\n",
      "                           PRE 2023.02.02/\n",
      "                           PRE 2023.02.03/\n",
      "                           PRE 2023.02.04/\n",
      "                           PRE 2023.02.05/\n",
      "                           PRE 2023.02.06/\n",
      "                           PRE 2023.02.07/\n",
      "                           PRE 2023.04.14/\n",
      "                           PRE 2023.04.15/\n",
      "                           PRE 2023.04.16/\n",
      "                           PRE 2023.04.17/\n",
      "                           PRE 2023.04.18/\n",
      "                           PRE 2023.04.19/\n",
      "                           PRE 2023.04.20/\n",
      "                           PRE 2023.04.21/\n",
      "                           PRE 2023.04.22/\n",
      "                           PRE 2023.04.23/\n",
      "2023-04-27 17:42:55      16392 sym\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if AWS_ACCESS_KEY_ID is not None:\n",
    "    cp = f\"\"\"\n",
    "export AWS_ACCESS_KEY_ID={AWS_ACCESS_KEY_ID}\n",
    "export AWS_SECRET_ACCESS_KEY={AWS_SECRET_ACCESS_KEY}\n",
    "export AWS_SESSION_TOKEN={AWS_SESSION_TOKEN}\n",
    "\n",
    "aws s3 sync  --exclude .DS_Store {SOURCE_DATA_DIR} {S3_DEST}\n",
    "aws s3 ls {S3_DEST}\n",
    "\"\"\"\n",
    "else:\n",
    "    cp = f\"\"\"\n",
    "aws s3 sync  --exclude .DS_Store {SOURCE_DATA_DIR} {S3_DEST}\n",
    "aws s3 ls {S3_DEST}\n",
    "\"\"\"\n",
    "    \n",
    "# execute the S3 copy\n",
    "os.system(cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67476efe-d308-4158-9e24-8fbe71509f76",
   "metadata": {},
   "source": [
    "## 3. Create database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d00c39-876a-4bba-ab66-a3aa4fb9b65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING Database: create_delete_db\n",
      "CREATED Database: create_delete_db\n",
      "{\n",
      "    \"createdTimestamp\": \"2023-05-31 15:23:00.011000+00:00\",\n",
      "    \"databaseArn\": \"arn:aws:finspace:us-east-1:612841383594:kxEnvironment/itcdoumzc5cixt5vh4t6dp/kxDatabase/create_delete_db\",\n",
      "    \"databaseName\": \"create_delete_db\",\n",
      "    \"description\": \"Welcome kdb database\",\n",
      "    \"environmentId\": \"itcdoumzc5cixt5vh4t6dp\",\n",
      "    \"lastModifiedTimestamp\": \"2023-05-31 15:23:00.011000+00:00\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# assume it exists\n",
    "create_db=False\n",
    "\n",
    "try:\n",
    "    resp = client.get_kx_database(environmentId=ENV_ID, databaseName=DB_NAME)\n",
    "    resp.pop('ResponseMetadata', None)\n",
    "except:\n",
    "    # does not exist, will create\n",
    "    create_db=True\n",
    "\n",
    "if create_db:\n",
    "    print(f\"CREATING Database: {DB_NAME}\")\n",
    "    resp = client.create_kx_database(environmentId=ENV_ID, databaseName=DB_NAME, description=\"Welcome kdb database\")\n",
    "    resp.pop('ResponseMetadata', None)\n",
    "\n",
    "    print(f\"CREATED Database: {DB_NAME}\")\n",
    "\n",
    "print(json.dumps(resp,sort_keys=True,indent=4,default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c84b3-2243-4abb-9032-8ae77a5e31f7",
   "metadata": {},
   "source": [
    "## 4. Add HDB data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60b3a8df-c7ed-4837-99e3-07d95e7fbac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changeset...\n",
      "{\n",
      "    \"changeRequests\": [\n",
      "        {\n",
      "            \"changeType\": \"PUT\",\n",
      "            \"dbPath\": \"/2023.04.23/\",\n",
      "            \"s3Path\": \"s3://kdb-demo-612841383594/data/hdb/2023.04.23/\"\n",
      "        },\n",
      "        {\n",
      "            \"changeType\": \"PUT\",\n",
      "            \"dbPath\": \"/2023.04.15/\",\n",
      "            \"s3Path\": \"s3://kdb-demo-612841383594/data/hdb/2023.04.15/\"\n",
      "        },\n",
      "        {\n",
      "            \"changeType\": \"PUT\",\n",
      "            \"dbPath\": \"/2023.04.14/\",\n",
      "            \"s3Path\": \"s3://kdb-demo-612841383594/data/hdb/2023.04.14/\"\n",
      "        },\n",
      "        {\n",
      "            \"changeType\": \"PUT\",\n",
      "            \"dbPath\": \"/2023.04.22/\",\n",
      "            \"s3Path\": \"s3://kdb-demo-612841383594/data/hdb/2023.04.22/\"\n",
      "        },\n",
      "        {\n",
      "            \"changeType\": \"PUT\",\n",
      "            \"dbPath\": \"/2023.04.18/\",\n",
      "            \"s3Path\": \"s3://kdb-demo-612841383594/data/hdb/2023.04.18/\"\n",
      "        },\n",
      "        {\n",
      "            \"changeType\": \"PUT\",\n",
      "            \"dbPath\": \"/2023.04.20/\",\n",
      "            \"s3Path\": \"s3://kdb-demo-612841383594/data/hdb/2023.04.20/\"\n",
      "        },\n",
      "        {\n",
      "            \"changeType\": \"PUT\",\n",
      "            \"dbPath\": \"/2023.04.16/\",\n",
      "            \"s3Path\": \"s3://kdb-demo-612841383594/data/hdb/2023.04.16/\"\n",
      "        },\n",
      "        {\n",
      "            \"changeType\": \"PUT\",\n",
      "            \"dbPath\": \"/2023.04.17/\",\n",
      "            \"s3Path\": \"s3://kdb-demo-612841383594/data/hdb/2023.04.17/\"\n",
      "        },\n",
      "        {\n",
      "            \"changeType\": \"PUT\",\n",
      "            \"dbPath\": \"/2023.04.21/\",\n",
      "            \"s3Path\": \"s3://kdb-demo-612841383594/data/hdb/2023.04.21/\"\n",
      "        },\n",
      "        {\n",
      "            \"changeType\": \"PUT\",\n",
      "            \"dbPath\": \"/2023.04.19/\",\n",
      "            \"s3Path\": \"s3://kdb-demo-612841383594/data/hdb/2023.04.19/\"\n",
      "        },\n",
      "        {\n",
      "            \"changeType\": \"PUT\",\n",
      "            \"dbPath\": \"/\",\n",
      "            \"s3Path\": \"s3://kdb-demo-612841383594/data/hdb/sym\"\n",
      "        }\n",
      "    ],\n",
      "    \"changesetId\": \"nsQ5M93T4nKfI0KaAWPH3w\",\n",
      "    \"createdTimestamp\": \"2023-05-31 15:23:00.905000+00:00\",\n",
      "    \"databaseName\": \"create_delete_db\",\n",
      "    \"environmentId\": \"itcdoumzc5cixt5vh4t6dp\",\n",
      "    \"lastModifiedTimestamp\": \"2023-05-31 15:23:00.905000+00:00\",\n",
      "    \"status\": \"PENDING\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "changes=[]\n",
    "\n",
    "for f in os.listdir(\"hdb\"):\n",
    "    if os.path.isdir(f\"hdb/{f}\"):\n",
    "        changes.append( { 'changeType': 'PUT', 's3Path': f\"{S3_DEST}{f}/\", 'dbPath': f\"/{f}/\" } )\n",
    "    else:\n",
    "        changes.append( { 'changeType': 'PUT', 's3Path': f\"{S3_DEST}{f}\", 'dbPath': f\"/\" } )\n",
    "        \n",
    "resp = client.create_kx_changeset(environmentId=ENV_ID, databaseName=DB_NAME, \n",
    "    changeRequests=changes)\n",
    "\n",
    "resp.pop('ResponseMetadata', None)\n",
    "changeset_id = resp['changesetId']\n",
    "\n",
    "print(\"Changeset...\")\n",
    "print(json.dumps(resp,sort_keys=True,indent=4,default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b344419-1261-43a3-89aa-f682ec54b0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status is IN_PROGRESS, total wait 0:00:00, waiting 10 sec ...\n",
      "Status is IN_PROGRESS, total wait 0:00:10, waiting 10 sec ...\n",
      "Status is IN_PROGRESS, total wait 0:00:20, waiting 10 sec ...\n",
      "Status is IN_PROGRESS, total wait 0:00:30, waiting 10 sec ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'changesetId': 'nsQ5M93T4nKfI0KaAWPH3w',\n",
       " 'databaseName': 'create_delete_db',\n",
       " 'environmentId': 'itcdoumzc5cixt5vh4t6dp',\n",
       " 'changeRequests': [{'changeType': 'PUT',\n",
       "   's3Path': 's3://kdb-demo-612841383594/data/hdb/2023.04.23/',\n",
       "   'dbPath': '/2023.04.23/'},\n",
       "  {'changeType': 'PUT',\n",
       "   's3Path': 's3://kdb-demo-612841383594/data/hdb/2023.04.15/',\n",
       "   'dbPath': '/2023.04.15/'},\n",
       "  {'changeType': 'PUT',\n",
       "   's3Path': 's3://kdb-demo-612841383594/data/hdb/2023.04.14/',\n",
       "   'dbPath': '/2023.04.14/'},\n",
       "  {'changeType': 'PUT',\n",
       "   's3Path': 's3://kdb-demo-612841383594/data/hdb/2023.04.22/',\n",
       "   'dbPath': '/2023.04.22/'},\n",
       "  {'changeType': 'PUT',\n",
       "   's3Path': 's3://kdb-demo-612841383594/data/hdb/2023.04.18/',\n",
       "   'dbPath': '/2023.04.18/'},\n",
       "  {'changeType': 'PUT',\n",
       "   's3Path': 's3://kdb-demo-612841383594/data/hdb/2023.04.20/',\n",
       "   'dbPath': '/2023.04.20/'},\n",
       "  {'changeType': 'PUT',\n",
       "   's3Path': 's3://kdb-demo-612841383594/data/hdb/2023.04.16/',\n",
       "   'dbPath': '/2023.04.16/'},\n",
       "  {'changeType': 'PUT',\n",
       "   's3Path': 's3://kdb-demo-612841383594/data/hdb/2023.04.17/',\n",
       "   'dbPath': '/2023.04.17/'},\n",
       "  {'changeType': 'PUT',\n",
       "   's3Path': 's3://kdb-demo-612841383594/data/hdb/2023.04.21/',\n",
       "   'dbPath': '/2023.04.21/'},\n",
       "  {'changeType': 'PUT',\n",
       "   's3Path': 's3://kdb-demo-612841383594/data/hdb/2023.04.19/',\n",
       "   'dbPath': '/2023.04.19/'},\n",
       "  {'changeType': 'PUT',\n",
       "   's3Path': 's3://kdb-demo-612841383594/data/hdb/sym',\n",
       "   'dbPath': '/'}],\n",
       " 'createdTimestamp': datetime.datetime(2023, 5, 31, 15, 23, 0, 905000, tzinfo=tzlocal()),\n",
       " 'activeFromTimestamp': datetime.datetime(2023, 5, 31, 15, 23, 40, 108000, tzinfo=tzlocal()),\n",
       " 'lastModifiedTimestamp': datetime.datetime(2023, 5, 31, 15, 23, 0, 905000, tzinfo=tzlocal()),\n",
       " 'status': 'COMPLETED'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wait_for_changeset_status(client, ENV_ID, DB_NAME, changeset_id, show_wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c1d2691-fe9a-47a7-8b1c-55ee1283e702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Database: create_delete_db, Changesets: 1 \n",
      "====================================================================================================\n",
      "  Changeset: nsQ5M93T4nKfI0KaAWPH3w: Created: 2023-05-31 15:23:00.905000+00:00 (COMPLETED)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_90ef4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_90ef4_level0_col0\" class=\"col_heading level0 col0\" >changeType</th>\n",
       "      <th id=\"T_90ef4_level0_col1\" class=\"col_heading level0 col1\" >s3Path</th>\n",
       "      <th id=\"T_90ef4_level0_col2\" class=\"col_heading level0 col2\" >dbPath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_90ef4_row0_col0\" class=\"data row0 col0\" >PUT</td>\n",
       "      <td id=\"T_90ef4_row0_col1\" class=\"data row0 col1\" >s3://kdb-demo-612841383594/data/hdb/2023.04.23/</td>\n",
       "      <td id=\"T_90ef4_row0_col2\" class=\"data row0 col2\" >/2023.04.23/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_90ef4_row1_col0\" class=\"data row1 col0\" >PUT</td>\n",
       "      <td id=\"T_90ef4_row1_col1\" class=\"data row1 col1\" >s3://kdb-demo-612841383594/data/hdb/2023.04.15/</td>\n",
       "      <td id=\"T_90ef4_row1_col2\" class=\"data row1 col2\" >/2023.04.15/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_90ef4_row2_col0\" class=\"data row2 col0\" >PUT</td>\n",
       "      <td id=\"T_90ef4_row2_col1\" class=\"data row2 col1\" >s3://kdb-demo-612841383594/data/hdb/2023.04.14/</td>\n",
       "      <td id=\"T_90ef4_row2_col2\" class=\"data row2 col2\" >/2023.04.14/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_90ef4_row3_col0\" class=\"data row3 col0\" >PUT</td>\n",
       "      <td id=\"T_90ef4_row3_col1\" class=\"data row3 col1\" >s3://kdb-demo-612841383594/data/hdb/2023.04.22/</td>\n",
       "      <td id=\"T_90ef4_row3_col2\" class=\"data row3 col2\" >/2023.04.22/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_90ef4_row4_col0\" class=\"data row4 col0\" >PUT</td>\n",
       "      <td id=\"T_90ef4_row4_col1\" class=\"data row4 col1\" >s3://kdb-demo-612841383594/data/hdb/2023.04.18/</td>\n",
       "      <td id=\"T_90ef4_row4_col2\" class=\"data row4 col2\" >/2023.04.18/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_90ef4_row5_col0\" class=\"data row5 col0\" >PUT</td>\n",
       "      <td id=\"T_90ef4_row5_col1\" class=\"data row5 col1\" >s3://kdb-demo-612841383594/data/hdb/2023.04.20/</td>\n",
       "      <td id=\"T_90ef4_row5_col2\" class=\"data row5 col2\" >/2023.04.20/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_90ef4_row6_col0\" class=\"data row6 col0\" >PUT</td>\n",
       "      <td id=\"T_90ef4_row6_col1\" class=\"data row6 col1\" >s3://kdb-demo-612841383594/data/hdb/2023.04.16/</td>\n",
       "      <td id=\"T_90ef4_row6_col2\" class=\"data row6 col2\" >/2023.04.16/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_90ef4_row7_col0\" class=\"data row7 col0\" >PUT</td>\n",
       "      <td id=\"T_90ef4_row7_col1\" class=\"data row7 col1\" >s3://kdb-demo-612841383594/data/hdb/2023.04.17/</td>\n",
       "      <td id=\"T_90ef4_row7_col2\" class=\"data row7 col2\" >/2023.04.17/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_90ef4_row8_col0\" class=\"data row8 col0\" >PUT</td>\n",
       "      <td id=\"T_90ef4_row8_col1\" class=\"data row8 col1\" >s3://kdb-demo-612841383594/data/hdb/2023.04.21/</td>\n",
       "      <td id=\"T_90ef4_row8_col2\" class=\"data row8 col2\" >/2023.04.21/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_90ef4_row9_col0\" class=\"data row9 col0\" >PUT</td>\n",
       "      <td id=\"T_90ef4_row9_col1\" class=\"data row9 col1\" >s3://kdb-demo-612841383594/data/hdb/2023.04.19/</td>\n",
       "      <td id=\"T_90ef4_row9_col2\" class=\"data row9 col2\" >/2023.04.19/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_90ef4_row10_col0\" class=\"data row10 col0\" >PUT</td>\n",
       "      <td id=\"T_90ef4_row10_col1\" class=\"data row10 col1\" >s3://kdb-demo-612841383594/data/hdb/sym</td>\n",
       "      <td id=\"T_90ef4_row10_col2\" class=\"data row10 col2\" >/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fbd85b5b640>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "note_str = \"\"\n",
    "\n",
    "c_set_list = list_kx_changesets(client, ENV_ID, DB_NAME)\n",
    "\n",
    "if len(c_set_list) == 0:\n",
    "    note_str = \"<<Could not get changesets>>\"\n",
    "    \n",
    "print(100*\"=\")\n",
    "print(f\"Database: {DB_NAME}, Changesets: {len(c_set_list)} {note_str}\")\n",
    "print(100*\"=\")\n",
    "\n",
    "# sort by create time\n",
    "c_set_list = sorted(c_set_list, key=lambda d: d['createdTimestamp']) \n",
    "\n",
    "for c in c_set_list:\n",
    "    c_set_id = c['changesetId']\n",
    "    print(f\"  Changeset: {c_set_id}: Created: {c['createdTimestamp']} ({c['status']})\")\n",
    "    c_rqs = client.get_kx_changeset(environmentId=ENV_ID, databaseName=DB_NAME, changesetId=c_set_id)['changeRequests']\n",
    "\n",
    "    chs_pdf = pd.DataFrame.from_dict(c_rqs).style.hide(axis='index')\n",
    "    display(chs_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e42568f-5255-49d5-9bd9-0fd55298200d",
   "metadata": {},
   "source": [
    "## 5. Create a Cluster for the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a89c57ce-896b-47d4-b71e-5984c5e5a3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: code/ (stored 0%)\n",
      "updating: code/lib.q (stored 0%)\n",
      "updating: code/init.q (deflated 54%)\n",
      "upload: ./code.zip to s3://kdb-demo-612841383594/code/code.zip     \n",
      "2023-05-31 00:15:34      28450 basictick.zip\n",
      "2023-05-31 15:23:45        757 code.zip\n",
      "2023-05-31 10:19:36        652 taqcode.zip\n",
      "2023-05-31 10:24:55        787 welcomedb.zip\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zip the code\n",
    "os.system(f\"zip -r -X {CODEBASE}.zip {CODEBASE} -x '*.ipynb_checkpoints*'\")\n",
    "\n",
    "# copy code to S3\n",
    "\n",
    "if AWS_ACCESS_KEY_ID is not None:\n",
    "    cp = f\"\"\"\n",
    "export AWS_ACCESS_KEY_ID={AWS_ACCESS_KEY_ID}\n",
    "export AWS_SECRET_ACCESS_KEY={AWS_SECRET_ACCESS_KEY}\n",
    "export AWS_SESSION_TOKEN={AWS_SESSION_TOKEN}\n",
    "\n",
    "aws s3 cp  --exclude .DS_Store {CODEBASE}.zip s3://{S3_BUCKET}/code/{CODEBASE}.zip\n",
    "aws s3 ls s3://{S3_BUCKET}/code/\n",
    "\"\"\"\n",
    "else:\n",
    "    cp = f\"\"\"\n",
    "aws s3 cp  --exclude .DS_Store {CODEBASE}.zip s3://{S3_BUCKET}/code/{CODEBASE}.zip\n",
    "aws s3 ls s3://{S3_BUCKET}/code/\n",
    "\"\"\"\n",
    "    \n",
    "# execute the S3 copy\n",
    "os.system(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36142f08-5a68-4c22-993e-e169628133e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating: cluster_create_delete_db\n"
     ]
    }
   ],
   "source": [
    "print(f\"Creating: {CLUSTER_NAME}\")\n",
    "\n",
    "resp = client.create_kx_cluster(\n",
    "    environmentId=ENV_ID, \n",
    "    clusterName=CLUSTER_NAME,\n",
    "    clusterDescription=f\"Demo Cluster for database {DB_NAME}\",\n",
    "    clusterType='HDB',\n",
    "    releaseLabel = '1.0',\n",
    "    capacityConfiguration={ \"nodeType\": \"kx.s.xlarge\", \"nodeCount\": 3 },\n",
    "    databases=[{ \n",
    "        'databaseName': DB_NAME, \n",
    "        'cacheConfigurations': [\n",
    "            {'dbPaths':['/'], 'cacheType': 'CACHE_1000' }\n",
    "        ] \n",
    "    }],\n",
    "    cacheStorageConfigurations=[{ 'type': 'CACHE_1000', 'size':1200 }],\n",
    "    azMode=AZ_MODE,\n",
    "    availabilityZoneId=AZ_ID,\n",
    "    vpcConfiguration={ \n",
    "        'vpcId': VPC_ID,\n",
    "        'securityGroupIds': SECURITY_GROUPS,\n",
    "        'subnetIds': SUBNET_IDS,\n",
    "        'ipAddressType': 'IP_V4' },\n",
    "    code={ 's3Bucket': S3_BUCKET, 's3Key': CODE_PATH },\n",
    "    initializationScript=f\"{CODEBASE}/init.q\",\n",
    "    commandLineArguments=[\n",
    "        {'key': 's', 'value': '4'}, \n",
    "        {'key': 'dbname', 'value': DB_NAME}, \n",
    "        {'key': 'codebase', 'value': CODEBASE}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e32bdf1d-0f12-4d0e-8ac8-0c6a691d1896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '71b76ba7-68d0-457a-94f2-24122f15c87a',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/json',\n",
       "   'content-length': '1128',\n",
       "   'connection': 'keep-alive',\n",
       "   'date': 'Wed, 31 May 2023 15:23:53 GMT',\n",
       "   'x-amzn-requestid': '71b76ba7-68d0-457a-94f2-24122f15c87a',\n",
       "   'x-amz-apigw-id': 'Fyz0RGEioAMFm-w=',\n",
       "   'x-amzn-trace-id': 'Root=1-64776681-09e6a76e17ece19b2b85f2af',\n",
       "   'x-cache': 'Miss from cloudfront',\n",
       "   'via': '1.1 b2179245b8d8ae2b245dd8946895eb1e.cloudfront.net (CloudFront)',\n",
       "   'x-amz-cf-pop': 'IAD55-P1',\n",
       "   'x-amz-cf-id': 'gAQIQeb33bwr4apE-R8xSqZrmzScu0AjztPJn0tMby_zQN9ctZvUAQ=='},\n",
       "  'RetryAttempts': 0},\n",
       " 'status': 'PENDING',\n",
       " 'clusterName': 'cluster_create_delete_db',\n",
       " 'clusterType': 'HDB',\n",
       " 'databases': [{'databaseName': 'create_delete_db',\n",
       "   'cacheConfigurations': [{'cacheType': 'CACHE_1000', 'dbPaths': ['/']}],\n",
       "   'changesetId': 'nsQ5M93T4nKfI0KaAWPH3w'}],\n",
       " 'cacheStorageConfigurations': [{'type': 'CACHE_1000', 'size': 1200}],\n",
       " 'clusterDescription': 'Demo Cluster for database create_delete_db',\n",
       " 'capacityConfiguration': {'nodeType': 'kx.s.xlarge', 'nodeCount': 3},\n",
       " 'releaseLabel': '1.0',\n",
       " 'vpcConfiguration': {'vpcId': 'vpc-0e702dec545865b11',\n",
       "  'securityGroupIds': ['sg-018111774e795682d'],\n",
       "  'subnetIds': ['subnet-0f97cae6600859c17'],\n",
       "  'ipAddressType': 'IP_V4'},\n",
       " 'initializationScript': 'code/init.q',\n",
       " 'commandLineArguments': [{'key': 's', 'value': '4'},\n",
       "  {'key': 'dbname', 'value': 'create_delete_db'},\n",
       "  {'key': 'codebase', 'value': 'code'}],\n",
       " 'code': {'s3Bucket': 'kdb-demo-612841383594', 's3Key': 'code/code.zip'},\n",
       " 'lastModifiedTimestamp': datetime.datetime(2023, 5, 31, 15, 23, 52, 332000, tzinfo=tzlocal()),\n",
       " 'azMode': 'SINGLE',\n",
       " 'availabilityZoneId': 'use1-az4',\n",
       " 'createdTimestamp': datetime.datetime(2023, 5, 31, 15, 23, 52, 245000, tzinfo=tzlocal())}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c21dbb8-9878-441f-997b-f27164e1e6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: cluster_create_delete_db status is PENDING, total wait 0:00:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:00:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:01:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:01:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:02:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:02:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:03:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:03:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:04:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:04:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:05:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:05:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:06:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:06:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:07:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:07:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:08:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:08:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:09:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:09:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:10:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:10:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:11:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:11:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:12:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:12:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:13:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:13:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:14:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:14:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:15:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:15:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:16:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:16:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:17:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:17:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is CREATING, total wait 0:18:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is now RUNNING, total wait 0:18:30\n",
      "\n",
      "** DONE **\n"
     ]
    }
   ],
   "source": [
    "wait_for_cluster_status(client, environmentId=ENV_ID, clusterName=CLUSTER_NAME, show_wait=True)\n",
    "print()\n",
    "print(\"** DONE **\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1a5cac-c0f6-4478-8f67-0c1060fe986a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Get the connectionString\n",
    "This assumes that the IAM role exists and the user (KDB_USERNAME) have beed already added as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c63c186-d837-4185-9280-2a486425f05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: --------------------------------------------------------------------------------\n",
      "{\n",
      "    \"availabilityZoneId\": \"use1-az4\",\n",
      "    \"azMode\": \"SINGLE\",\n",
      "    \"cacheStorageConfigurations\": [\n",
      "        {\n",
      "            \"size\": 1200,\n",
      "            \"type\": \"CACHE_1000\"\n",
      "        }\n",
      "    ],\n",
      "    \"capacityConfiguration\": {\n",
      "        \"nodeCount\": 3,\n",
      "        \"nodeType\": \"kx.s.xlarge\"\n",
      "    },\n",
      "    \"clusterDescription\": \"Demo Cluster for database create_delete_db\",\n",
      "    \"clusterName\": \"cluster_create_delete_db\",\n",
      "    \"clusterType\": \"HDB\",\n",
      "    \"code\": {\n",
      "        \"s3Bucket\": \"kdb-demo-612841383594\",\n",
      "        \"s3Key\": \"code/code.zip\"\n",
      "    },\n",
      "    \"commandLineArguments\": [\n",
      "        {\n",
      "            \"key\": \"s\",\n",
      "            \"value\": \"4\"\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"dbname\",\n",
      "            \"value\": \"create_delete_db\"\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"codebase\",\n",
      "            \"value\": \"code\"\n",
      "        }\n",
      "    ],\n",
      "    \"createdTimestamp\": \"2023-05-31 15:23:52.245000+00:00\",\n",
      "    \"databases\": [\n",
      "        {\n",
      "            \"cacheConfigurations\": [\n",
      "                {\n",
      "                    \"cacheType\": \"CACHE_1000\",\n",
      "                    \"dbPaths\": [\n",
      "                        \"/\"\n",
      "                    ]\n",
      "                }\n",
      "            ],\n",
      "            \"changesetId\": \"nsQ5M93T4nKfI0KaAWPH3w\",\n",
      "            \"databaseName\": \"create_delete_db\"\n",
      "        }\n",
      "    ],\n",
      "    \"initializationScript\": \"code/init.q\",\n",
      "    \"lastModifiedTimestamp\": \"2023-05-31 15:42:40.298000+00:00\",\n",
      "    \"releaseLabel\": \"1.0\",\n",
      "    \"status\": \"RUNNING\",\n",
      "    \"vpcConfiguration\": {\n",
      "        \"ipAddressType\": \"IP_V4\",\n",
      "        \"securityGroupIds\": [\n",
      "            \"sg-018111774e795682d\"\n",
      "        ],\n",
      "        \"subnetIds\": [\n",
      "            \"subnet-0f97cae6600859c17\"\n",
      "        ],\n",
      "        \"vpcId\": \"vpc-0e702dec545865b11\"\n",
      "    }\n",
      "}\n"
     ]
    },
    {
     "ename": "AccessDeniedException",
     "evalue": "An error occurred (AccessDeniedException) when calling the GetKxConnectionString operation: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAccessDeniedException\u001b[0m                     Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Give permissions time to propogate after cluster creation....\u001b[39;00m\n\u001b[1;32m     17\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m25\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m conn_str \u001b[38;5;241m=\u001b[39m \u001b[43mget_kx_connection_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menvironmentId\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mENV_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclusterName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCLUSTER_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKDB_USERNAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mboto_session\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCopy into q: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m))\n",
      "File \u001b[0;32m~/notebooks/boto/managed_kx.py:275\u001b[0m, in \u001b[0;36mget_kx_connection_string\u001b[0;34m(client, environmentId, clusterName, userName, boto_session, endpoint_url)\u001b[0m\n\u001b[1;32m    268\u001b[0m cred_session \u001b[38;5;241m=\u001b[39m boto3\u001b[38;5;241m.\u001b[39mSession(\n\u001b[1;32m    269\u001b[0m     aws_access_key_id\u001b[38;5;241m=\u001b[39mcreds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccessKeyId\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    270\u001b[0m     aws_secret_access_key\u001b[38;5;241m=\u001b[39mcreds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSecretAccessKey\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    271\u001b[0m     aws_session_token\u001b[38;5;241m=\u001b[39mcreds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSessionToken\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    272\u001b[0m )\n\u001b[1;32m    274\u001b[0m cred_client \u001b[38;5;241m=\u001b[39m cred_session\u001b[38;5;241m.\u001b[39mclient(service_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinspace\u001b[39m\u001b[38;5;124m'\u001b[39m, endpoint_url\u001b[38;5;241m=\u001b[39mendpoint_url)\n\u001b[0;32m--> 275\u001b[0m resp\u001b[38;5;241m=\u001b[39m\u001b[43mcred_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_kx_connection_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43menvironmentId\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menvironmentId\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserArn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muserArn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclusterName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclusterName\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignedConnectionString\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/botocore/client.py:530\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[1;32m    529\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/botocore/client.py:964\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    962\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m parsed_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    963\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 964\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mAccessDeniedException\u001b[0m: An error occurred (AccessDeniedException) when calling the GetKxConnectionString operation: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    resp = client.get_kx_cluster(environmentId=ENV_ID, clusterName=CLUSTER_NAME)\n",
    "except client.exceptions.ResourceNotFoundException:\n",
    "    print(F\"Cluster: {CLUSTER_NAME} did not create\")\n",
    "    \n",
    "if resp['ResponseMetadata']['HTTPStatusCode'] != 200:\n",
    "    sys.stderr.write(\"Error:\\n {resp}\")\n",
    "else:\n",
    "    resp.pop('ResponseMetadata', None)\n",
    "\n",
    "kx_cluster = resp\n",
    "\n",
    "print(\"Cluster: \"+(\"-\"*80))\n",
    "print(json.dumps(kx_cluster, sort_keys=True, indent=4, default=str))\n",
    "\n",
    "# Give permissions time to propogate after cluster creation....\n",
    "time.sleep(25)\n",
    "\n",
    "conn_str = get_kx_connection_string(client, environmentId=ENV_ID, clusterName=CLUSTER_NAME, userName=KDB_USERNAME, boto_session=session)\n",
    "\n",
    "print (\"\")\n",
    "print(\"Copy into q: \"+(\"-\"*80))\n",
    "print(f\"\"\"\n",
    "/ Cluster: {CLUSTER_NAME}\n",
    "hdb_conn:\"{conn_str}\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec5839-e519-42d2-ab62-a524cee0bdfc",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "941c540a-f4ed-46a1-a7ba-7e125b72501c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_98562\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_98562_level0_col0\" class=\"col_heading level0 col0\" >databaseName</th>\n",
       "      <th id=\"T_98562_level0_col1\" class=\"col_heading level0 col1\" >createdTimestamp</th>\n",
       "      <th id=\"T_98562_level0_col2\" class=\"col_heading level0 col2\" >lastModifiedTimestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_98562_row0_col0\" class=\"data row0 col0\" >TAQ_2021_2D</td>\n",
       "      <td id=\"T_98562_row0_col1\" class=\"data row0 col1\" >2023-05-30 22:54:17.321000+00:00</td>\n",
       "      <td id=\"T_98562_row0_col2\" class=\"data row0 col2\" >2023-05-30 22:54:17.945000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_98562_row1_col0\" class=\"data row1 col0\" >create_delete_db</td>\n",
       "      <td id=\"T_98562_row1_col1\" class=\"data row1 col1\" >2023-05-31 13:52:16.839000+00:00</td>\n",
       "      <td id=\"T_98562_row1_col2\" class=\"data row1 col2\" >2023-05-31 13:52:17.712000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_98562_row2_col0\" class=\"data row2 col0\" >TAQ_2021H1</td>\n",
       "      <td id=\"T_98562_row2_col1\" class=\"data row2 col1\" >2023-05-30 22:55:27.556000+00:00</td>\n",
       "      <td id=\"T_98562_row2_col2\" class=\"data row2 col2\" >2023-05-30 22:59:43.785000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_98562_row3_col0\" class=\"data row3 col0\" >welcomedb</td>\n",
       "      <td id=\"T_98562_row3_col1\" class=\"data row3 col1\" >2023-05-30 22:53:12.481000+00:00</td>\n",
       "      <td id=\"T_98562_row3_col2\" class=\"data row3 col2\" >2023-05-30 22:53:13.165000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_98562_row4_col0\" class=\"data row4 col0\" >basictickdb</td>\n",
       "      <td id=\"T_98562_row4_col1\" class=\"data row4 col1\" >2023-05-30 23:21:59.431000+00:00</td>\n",
       "      <td id=\"T_98562_row4_col2\" class=\"data row4 col2\" >2023-05-31 00:18:15.745000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f92e42e0700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:00:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:00:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:01:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:01:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:02:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:02:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:03:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:03:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:04:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:04:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:05:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:05:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:06:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:06:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:07:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:07:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:08:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:08:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:09:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:09:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:10:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:10:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:11:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:11:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:12:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:12:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:13:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:13:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:14:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:14:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:15:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:15:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:16:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:16:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:17:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:17:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:18:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:18:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:19:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:19:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:20:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:20:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:21:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:21:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:22:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:22:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:23:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:23:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:24:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:24:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:25:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:25:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:26:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:26:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:27:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:27:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:28:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:28:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:29:00, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:29:30, waiting 30 sec ...\n",
      "Cluster: cluster_create_delete_db status is DELETING, total wait 0:30:00, waiting 30 sec ...\n",
      "\n",
      "** DONE **\n"
     ]
    }
   ],
   "source": [
    "# Cluster Deletion\n",
    "# ------------------------------------------------------------\n",
    "db_list = list_kx_databases(client, environmentId=ENV_ID)\n",
    "db_list\n",
    "\n",
    "db_pdf = pd.DataFrame.from_dict(db_list).style.hide(axis='index')\n",
    "display(db_pdf)\n",
    "print(\"\")\n",
    "\n",
    "cluster_deleted=False\n",
    "\n",
    "if DELETE_CLUSTER:   \n",
    "    # list all clusters\n",
    "    resp=client.get_kx_cluster(environmentId=ENV_ID, clusterName=CLUSTER_NAME)\n",
    "    \n",
    "    if resp['ResponseMetadata']['HTTPStatusCode'] != 200:\n",
    "        sys.stderr.write(\"Error:\\n {resp}\")\n",
    "    else:\n",
    "        resp.pop('ResponseMetadata', None)\n",
    "\n",
    "    if resp['status'] != 'DELETING':\n",
    "        try:\n",
    "            resp = client.delete_kx_cluster(environmentId=ENV_ID, clusterName=CLUSTER_NAME)\n",
    "            if resp['ResponseMetadata']['HTTPStatusCode'] != 200:\n",
    "                sys.stderr.write(\"Error:\\n {resp}\")\n",
    "            else:\n",
    "                resp.pop('ResponseMetadata', None)\n",
    "        except Exception as e: \n",
    "            sys.stderr.write(f\"Error deleting cluster: {CLUSTER_NAME}\\n{e}\")\n",
    "            cluster_deleted = False\n",
    "\n",
    "    try:\n",
    "        wait_for_cluster_status(client, environmentId=ENV_ID, clusterName=CLUSTER_NAME, status='DELETED', show_wait=True)\n",
    "        print()\n",
    "        print(\"** DONE **\")\n",
    "\n",
    "        cluster_deleted = True\n",
    "    except client.exceptions.ResourceNotFoundException:\n",
    "        cluster_deleted = True\n",
    "else:\n",
    "    print(f\"DELETE_CLUSTER: {DELETE_CLUSTER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66da3a6c-c7ba-46f1-8908-198f36b3349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database Deletion\n",
    "# Requires cluster to have been deleted\n",
    "if DELETE_DATABASE:\n",
    "    if cluster_deleted:\n",
    "        # if the database exists, delete it\n",
    "        if has_database(client, environmentId=ENV_ID, databaseName=DB_NAME):\n",
    "            try:\n",
    "                resp = client.delete_kx_database(environmentId=ENV_ID, databaseName=DB_NAME)\n",
    "                if resp['ResponseMetadata']['HTTPStatusCode'] != 200:\n",
    "                    sys.stderr.write(\"Error:\\n {resp}\")\n",
    "                else:\n",
    "                    resp.pop('ResponseMetadata', None)\n",
    "\n",
    "                resp\n",
    "            except Exception as e: \n",
    "                sys.stderr.write(f\"Error: \\n{e}\")\n",
    "        else:\n",
    "            print(f\"Database already deleted: {DB_NAME} \")\n",
    "    else:\n",
    "        print(f\"Cluster deleted? {cluster_deleted}, will not delete database if cluster not deleted\")\n",
    "else:\n",
    "    print(f\"DELETE_DATABASE: {DELETE_DATABASE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2346146-b86a-4d95-9f82-5b4e4705acd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_5cfa3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_5cfa3_level0_col0\" class=\"col_heading level0 col0\" >databaseName</th>\n",
       "      <th id=\"T_5cfa3_level0_col1\" class=\"col_heading level0 col1\" >createdTimestamp</th>\n",
       "      <th id=\"T_5cfa3_level0_col2\" class=\"col_heading level0 col2\" >lastModifiedTimestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_5cfa3_row0_col0\" class=\"data row0 col0\" >TAQ_2021H1</td>\n",
       "      <td id=\"T_5cfa3_row0_col1\" class=\"data row0 col1\" >2023-05-30 22:55:27.556000+00:00</td>\n",
       "      <td id=\"T_5cfa3_row0_col2\" class=\"data row0 col2\" >2023-05-30 22:59:43.785000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5cfa3_row1_col0\" class=\"data row1 col0\" >TAQ_2021_2D</td>\n",
       "      <td id=\"T_5cfa3_row1_col1\" class=\"data row1 col1\" >2023-05-30 22:54:17.321000+00:00</td>\n",
       "      <td id=\"T_5cfa3_row1_col2\" class=\"data row1 col2\" >2023-05-30 22:54:17.945000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5cfa3_row2_col0\" class=\"data row2 col0\" >basictickdb</td>\n",
       "      <td id=\"T_5cfa3_row2_col1\" class=\"data row2 col1\" >2023-05-30 23:21:59.431000+00:00</td>\n",
       "      <td id=\"T_5cfa3_row2_col2\" class=\"data row2 col2\" >2023-05-31 00:18:15.745000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5cfa3_row3_col0\" class=\"data row3 col0\" >welcomedb</td>\n",
       "      <td id=\"T_5cfa3_row3_col1\" class=\"data row3 col1\" >2023-05-30 22:53:12.481000+00:00</td>\n",
       "      <td id=\"T_5cfa3_row3_col2\" class=\"data row3 col2\" >2023-05-30 22:53:13.165000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f92e42df610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "db_list = list_kx_databases(client, environmentId=ENV_ID)\n",
    "db_list=sorted(db_list, key=lambda d: d['databaseName']) \n",
    "\n",
    "db_pdf = pd.DataFrame.from_dict(db_list).style.hide(axis='index')\n",
    "display(db_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ae3d31a-c70d-4a4c-935f-5d86f700a07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_5b1f2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_5b1f2_level0_col0\" class=\"col_heading level0 col0\" >clusterName</th>\n",
       "      <th id=\"T_5b1f2_level0_col1\" class=\"col_heading level0 col1\" >status</th>\n",
       "      <th id=\"T_5b1f2_level0_col2\" class=\"col_heading level0 col2\" >clusterType</th>\n",
       "      <th id=\"T_5b1f2_level0_col3\" class=\"col_heading level0 col3\" >capacityConfiguration</th>\n",
       "      <th id=\"T_5b1f2_level0_col4\" class=\"col_heading level0 col4\" >commandLineArguments</th>\n",
       "      <th id=\"T_5b1f2_level0_col5\" class=\"col_heading level0 col5\" >clusterDescription</th>\n",
       "      <th id=\"T_5b1f2_level0_col6\" class=\"col_heading level0 col6\" >lastModifiedTimestamp</th>\n",
       "      <th id=\"T_5b1f2_level0_col7\" class=\"col_heading level0 col7\" >createdTimestamp</th>\n",
       "      <th id=\"T_5b1f2_level0_col8\" class=\"col_heading level0 col8\" >databaseName</th>\n",
       "      <th id=\"T_5b1f2_level0_col9\" class=\"col_heading level0 col9\" >cacheConfigurations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_5b1f2_row0_col0\" class=\"data row0 col0\" >GATEWAY_basictickdb_20230530</td>\n",
       "      <td id=\"T_5b1f2_row0_col1\" class=\"data row0 col1\" >RUNNING</td>\n",
       "      <td id=\"T_5b1f2_row0_col2\" class=\"data row0 col2\" >GATEWAY</td>\n",
       "      <td id=\"T_5b1f2_row0_col3\" class=\"data row0 col3\" >{'nodeType': 'kx.s.4xlarge', 'nodeCount': 1}</td>\n",
       "      <td id=\"T_5b1f2_row0_col4\" class=\"data row0 col4\" >[{'key': 's', 'value': '8'}, {'key': 'dbdir', 'value': 'basictickdb'}, {'key': 'codedir', 'value': 'basictick'}, {'key': 'rdb_name', 'value': 'RDB_basictickdb_20230530'}, {'key': 'hdb_name', 'value': 'HDB_basictickdb_20230530'}]</td>\n",
       "      <td id=\"T_5b1f2_row0_col5\" class=\"data row0 col5\" >Created with create_GW notebook</td>\n",
       "      <td id=\"T_5b1f2_row0_col6\" class=\"data row0 col6\" >2023-05-31 00:29:39.774000+00:00</td>\n",
       "      <td id=\"T_5b1f2_row0_col7\" class=\"data row0 col7\" >2023-05-31 00:15:38.003000+00:00</td>\n",
       "      <td id=\"T_5b1f2_row0_col8\" class=\"data row0 col8\" >None</td>\n",
       "      <td id=\"T_5b1f2_row0_col9\" class=\"data row0 col9\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5b1f2_row1_col0\" class=\"data row1 col0\" >HDB_TAQ_2021H1</td>\n",
       "      <td id=\"T_5b1f2_row1_col1\" class=\"data row1 col1\" >RUNNING</td>\n",
       "      <td id=\"T_5b1f2_row1_col2\" class=\"data row1 col2\" >HDB</td>\n",
       "      <td id=\"T_5b1f2_row1_col3\" class=\"data row1 col3\" >{'nodeType': 'kx.s.32xlarge', 'nodeCount': 2}</td>\n",
       "      <td id=\"T_5b1f2_row1_col4\" class=\"data row1 col4\" >[{'key': 's', 'value': '32'}, {'key': 'dbname', 'value': 'TAQ_2021H1'}, {'key': 'codebase', 'value': 'taqcode'}]</td>\n",
       "      <td id=\"T_5b1f2_row1_col5\" class=\"data row1 col5\" >Created with create_cluster_TAQ_H1 notebook</td>\n",
       "      <td id=\"T_5b1f2_row1_col6\" class=\"data row1 col6\" >2023-05-31 10:40:45.063000+00:00</td>\n",
       "      <td id=\"T_5b1f2_row1_col7\" class=\"data row1 col7\" >2023-05-31 10:19:39.315000+00:00</td>\n",
       "      <td id=\"T_5b1f2_row1_col8\" class=\"data row1 col8\" >TAQ_2021H1</td>\n",
       "      <td id=\"T_5b1f2_row1_col9\" class=\"data row1 col9\" >[{'cacheType': 'CACHE_1000', 'dbPaths': ['/2021.01.04/', '/2021.01.05/', '/2021.01.06/', '/2021.01.07/', '/2021.01.08/', '/2021.01.11/', '/2021.01.12/', '/2021.01.13/', '/2021.01.14/', '/2021.01.15/', '/2021.01.19/', '/2021.01.20/', '/2021.01.21/', '/2021.01.22/', '/2021.01.25/', '/2021.01.26/', '/2021.01.27/', '/2021.01.28/', '/2021.01.29/', '/2021.02.01/', '/2021.02.02/', '/2021.02.03/', '/2021.02.04/', '/2021.02.05/']}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5b1f2_row2_col0\" class=\"data row2 col0\" >HDB_TAQ_2021_2D</td>\n",
       "      <td id=\"T_5b1f2_row2_col1\" class=\"data row2 col1\" >RUNNING</td>\n",
       "      <td id=\"T_5b1f2_row2_col2\" class=\"data row2 col2\" >HDB</td>\n",
       "      <td id=\"T_5b1f2_row2_col3\" class=\"data row2 col3\" >{'nodeType': 'kx.s.32xlarge', 'nodeCount': 2}</td>\n",
       "      <td id=\"T_5b1f2_row2_col4\" class=\"data row2 col4\" >[{'key': 's', 'value': '8'}, {'key': 'dbname', 'value': 'TAQ_2021_2D'}, {'key': 'codebase', 'value': 'taqcode'}]</td>\n",
       "      <td id=\"T_5b1f2_row2_col5\" class=\"data row2 col5\" >Created with create_cluster_TAQ_2D notebook</td>\n",
       "      <td id=\"T_5b1f2_row2_col6\" class=\"data row2 col6\" >2023-05-31 10:40:17.015000+00:00</td>\n",
       "      <td id=\"T_5b1f2_row2_col7\" class=\"data row2 col7\" >2023-05-31 10:19:34.957000+00:00</td>\n",
       "      <td id=\"T_5b1f2_row2_col8\" class=\"data row2 col8\" >TAQ_2021_2D</td>\n",
       "      <td id=\"T_5b1f2_row2_col9\" class=\"data row2 col9\" >[{'cacheType': 'CACHE_1000', 'dbPaths': ['/2021.01.04/', '/2021.01.05/']}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5b1f2_row3_col0\" class=\"data row3 col0\" >HDB_basictickdb_20230530</td>\n",
       "      <td id=\"T_5b1f2_row3_col1\" class=\"data row3 col1\" >RUNNING</td>\n",
       "      <td id=\"T_5b1f2_row3_col2\" class=\"data row3 col2\" >HDB</td>\n",
       "      <td id=\"T_5b1f2_row3_col3\" class=\"data row3 col3\" >{'nodeType': 'kx.s.xlarge', 'nodeCount': 3}</td>\n",
       "      <td id=\"T_5b1f2_row3_col4\" class=\"data row3 col4\" >[{'key': 's', 'value': '8'}, {'key': 'dbdir', 'value': 'basictickdb'}, {'key': 'codedir', 'value': 'basictick'}]</td>\n",
       "      <td id=\"T_5b1f2_row3_col5\" class=\"data row3 col5\" >Created with create_HDB for basic_tick notebook</td>\n",
       "      <td id=\"T_5b1f2_row3_col6\" class=\"data row3 col6\" >2023-05-31 00:44:28.283000+00:00</td>\n",
       "      <td id=\"T_5b1f2_row3_col7\" class=\"data row3 col7\" >2023-05-30 23:52:04.592000+00:00</td>\n",
       "      <td id=\"T_5b1f2_row3_col8\" class=\"data row3 col8\" >basictickdb</td>\n",
       "      <td id=\"T_5b1f2_row3_col9\" class=\"data row3 col9\" >[{'cacheType': 'CACHE_1000', 'dbPaths': ['/']}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5b1f2_row4_col0\" class=\"data row4 col0\" >HDB_welcomedb</td>\n",
       "      <td id=\"T_5b1f2_row4_col1\" class=\"data row4 col1\" >RUNNING</td>\n",
       "      <td id=\"T_5b1f2_row4_col2\" class=\"data row4 col2\" >HDB</td>\n",
       "      <td id=\"T_5b1f2_row4_col3\" class=\"data row4 col3\" >{'nodeType': 'kx.s.2xlarge', 'nodeCount': 3}</td>\n",
       "      <td id=\"T_5b1f2_row4_col4\" class=\"data row4 col4\" >[{'key': 's', 'value': '4'}, {'key': 'dbname', 'value': 'welcomedb'}, {'key': 'codebase', 'value': 'code'}]</td>\n",
       "      <td id=\"T_5b1f2_row4_col5\" class=\"data row4 col5\" >Created with create_cluster_HDB notebook</td>\n",
       "      <td id=\"T_5b1f2_row4_col6\" class=\"data row4 col6\" >2023-05-30 23:13:20.948000+00:00</td>\n",
       "      <td id=\"T_5b1f2_row4_col7\" class=\"data row4 col7\" >2023-05-30 22:56:11.773000+00:00</td>\n",
       "      <td id=\"T_5b1f2_row4_col8\" class=\"data row4 col8\" >welcomedb</td>\n",
       "      <td id=\"T_5b1f2_row4_col9\" class=\"data row4 col9\" >[{'cacheType': 'CACHE_1000', 'dbPaths': ['/']}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5b1f2_row5_col0\" class=\"data row5 col0\" >RDB_basictickdb_20230530</td>\n",
       "      <td id=\"T_5b1f2_row5_col1\" class=\"data row5 col1\" >RUNNING</td>\n",
       "      <td id=\"T_5b1f2_row5_col2\" class=\"data row5 col2\" >RDB</td>\n",
       "      <td id=\"T_5b1f2_row5_col3\" class=\"data row5 col3\" >{'nodeType': 'kx.s.2xlarge', 'nodeCount': 1}</td>\n",
       "      <td id=\"T_5b1f2_row5_col4\" class=\"data row5 col4\" >[{'key': 's', 'value': '8'}, {'key': 'dbdir', 'value': 'basictickdb'}, {'key': 'codedir', 'value': 'basictick'}, {'key': 'tphostfile', 'value': 'tickerplant2'}]</td>\n",
       "      <td id=\"T_5b1f2_row5_col5\" class=\"data row5 col5\" >Created with create_RDB notebook</td>\n",
       "      <td id=\"T_5b1f2_row5_col6\" class=\"data row5 col6\" >2023-05-31 00:13:16.692000+00:00</td>\n",
       "      <td id=\"T_5b1f2_row5_col7\" class=\"data row5 col7\" >2023-05-30 23:59:27.832000+00:00</td>\n",
       "      <td id=\"T_5b1f2_row5_col8\" class=\"data row5 col8\" >basictickdb</td>\n",
       "      <td id=\"T_5b1f2_row5_col9\" class=\"data row5 col9\" >[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5b1f2_row6_col0\" class=\"data row6 col0\" >RDB_welcomedb</td>\n",
       "      <td id=\"T_5b1f2_row6_col1\" class=\"data row6 col1\" >RUNNING</td>\n",
       "      <td id=\"T_5b1f2_row6_col2\" class=\"data row6 col2\" >RDB</td>\n",
       "      <td id=\"T_5b1f2_row6_col3\" class=\"data row6 col3\" >{'nodeType': 'kx.s.2xlarge', 'nodeCount': 1}</td>\n",
       "      <td id=\"T_5b1f2_row6_col4\" class=\"data row6 col4\" >[{'key': 's', 'value': '8'}, {'key': 'dbname', 'value': 'welcomedb'}, {'key': 'codebase', 'value': 'code'}]</td>\n",
       "      <td id=\"T_5b1f2_row6_col5\" class=\"data row6 col5\" >Created with create_cluster_RDB notebook</td>\n",
       "      <td id=\"T_5b1f2_row6_col6\" class=\"data row6 col6\" >2023-05-30 23:10:28.477000+00:00</td>\n",
       "      <td id=\"T_5b1f2_row6_col7\" class=\"data row6 col7\" >2023-05-30 22:56:52.812000+00:00</td>\n",
       "      <td id=\"T_5b1f2_row6_col8\" class=\"data row6 col8\" >welcomedb</td>\n",
       "      <td id=\"T_5b1f2_row6_col9\" class=\"data row6 col9\" >[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_5b1f2_row7_col0\" class=\"data row7 col0\" >cluster_welcomedb</td>\n",
       "      <td id=\"T_5b1f2_row7_col1\" class=\"data row7 col1\" >RUNNING</td>\n",
       "      <td id=\"T_5b1f2_row7_col2\" class=\"data row7 col2\" >HDB</td>\n",
       "      <td id=\"T_5b1f2_row7_col3\" class=\"data row7 col3\" >{'nodeType': 'kx.s.xlarge', 'nodeCount': 3}</td>\n",
       "      <td id=\"T_5b1f2_row7_col4\" class=\"data row7 col4\" >[{'key': 's', 'value': '4'}, {'key': 'dbname', 'value': 'welcomedb'}, {'key': 'codebase', 'value': 'welcomedb'}]</td>\n",
       "      <td id=\"T_5b1f2_row7_col5\" class=\"data row7 col5\" >Demo Cluster for database welcomedb</td>\n",
       "      <td id=\"T_5b1f2_row7_col6\" class=\"data row7 col6\" >2023-05-30 23:10:58.551000+00:00</td>\n",
       "      <td id=\"T_5b1f2_row7_col7\" class=\"data row7 col7\" >2023-05-30 22:53:31.356000+00:00</td>\n",
       "      <td id=\"T_5b1f2_row7_col8\" class=\"data row7 col8\" >welcomedb</td>\n",
       "      <td id=\"T_5b1f2_row7_col9\" class=\"data row7 col9\" >[{'cacheType': 'CACHE_1000', 'dbPaths': ['/']}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f92e4230940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Run: 2023-05-31 14:49:42.394627\n"
     ]
    }
   ],
   "source": [
    "cdf = get_clusters(client, ENV_ID)\n",
    "\n",
    "display(cdf)\n",
    "\n",
    "print( f\"Last Run: {datetime.datetime.now()}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe3a21-1bf9-47ba-b162-70ab5445b44f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
