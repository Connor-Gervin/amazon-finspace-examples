{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28bea13b-67bd-4a0e-8eab-3b8ffd37259e",
   "metadata": {},
   "source": [
    "# Welcome Notebook\n",
    "This notebook walks through the process of creating and populating your first database with FinSpace Managed KX.\n",
    "\n",
    "## Before you start\n",
    "Before you start this notebook, it is assumed you have the following:\n",
    "- FinSpace Managed KX environment created in AWS account\n",
    "- S3 staging bucket for data and code\n",
    "  - This notebook boto's profile and the Managed KX environment can access the bucket\n",
    "- Setup in ~/.aws directory\n",
    "  - config is set (json and region)\n",
    "  - default credentials are set (aws_access_key_id, aws_secret_access_key, aws_session_token)\n",
    "\n",
    "## Steps\n",
    "1. Untar hdb.tar.gz for the hdb data\n",
    "2. Upload hdb to staging S3 bucket\n",
    "3. Create database\n",
    "4. Add HDB data to database\n",
    "5. Create a Cluster\n",
    "6. Get the connectionString\n",
    "7. Query Cluster using PyKX\n",
    "\n",
    "## Managed kdb Insights Archtecture\n",
    "<img src=\"Managed kdb Insights-HDB Migration.png\"  width=\"50%\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d543f3-1cd5-4a0e-8be7-a9eb0ac35878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "from managed_kx import *\n",
    "from env_kdb_1 import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5265616-6aa4-4b7b-b038-8e26e71d19e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source data directory\n",
    "SOURCE_DATA_DIR=\"hdb\"\n",
    "\n",
    "# S3 bucket for external data and code\n",
    "S3_DEST=f\"s3://{S3_BUCKET}/data/{SOURCE_DATA_DIR}/\"\n",
    "CODEBASE=\"code\"\n",
    "CODE_PATH=f\"code/{CODEBASE}.zip\"\n",
    "\n",
    "NODE_COUNT=1\n",
    "CACHE_SIZE=1200\n",
    "\n",
    "# Managed KX Database and Cluster names to create\n",
    "DB_NAME=\"welcomedb\"\n",
    "DELETE_CLUSTER=False\n",
    "DELETE_DATABASE=False\n",
    "\n",
    "create_delete=True\n",
    "\n",
    "if create_delete:\n",
    "    TODAY=datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")    \n",
    "    DB_NAME=f\"create_delete_db_{TODAY}\"\n",
    "    DELETE_CLUSTER=True\n",
    "    DELETE_DATABASE=True\n",
    "\n",
    "CLUSTER_NAME=f\"cluster_{DB_NAME}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e054ddd-3313-4ac3-b0b3-3c93b55e977e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# triggers credential get\n",
    "session=None\n",
    "\n",
    "try:\n",
    "    subprocess.call([\"which\", \"ada\"])\n",
    "    os.system(f\"ada credentials update --account={ACCOUNT_ID} --provider=isengard --role=Admin --once\")\n",
    "except: \n",
    "    None\n",
    "\n",
    "if AWS_ACCESS_KEY_ID is None:\n",
    "    print(\"Using Defaults ...\")\n",
    "    # create AWS session: using access variables\n",
    "    session = boto3.Session()\n",
    "else:\n",
    "    print(\"Using variables ...\")\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "        aws_session_token=AWS_SESSION_TOKEN\n",
    "    )\n",
    "\n",
    "# create finspace client\n",
    "client = session.client(service_name='finspace', endpoint_url=ENDPOINT_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849f954c-7cfa-4b29-be4f-0854aa7cbd06",
   "metadata": {},
   "source": [
    "# 0. Environment Check\n",
    "Be sure the infrastructure ID has been entitled to the bucket you will be staging the HDB to. The environment will also need access to the KMX key used when creating the environment.\n",
    "\n",
    "## Permission Templates\n",
    "\n",
    "### S3 Permission\n",
    "Example of code and data access to the same S3 bucket.\n",
    "\n",
    "```\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"finspace.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:GetObjectTagging\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::S3_BUCKET/*\",\n",
    "                \"arn:aws:s3:::S3_BUCKET\"\n",
    "            ],\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"aws:SourceAccount\": \"ACCOUNT_ID\"\n",
    "                },\n",
    "                \"ArnEquals\": {\n",
    "                    \"aws:SourceArn\": \"arn:aws:finspace:us-east-1:ACCOUNT_ID:kxEnvironment/ENV_ID/*\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "### KMS Key\n",
    "Be sure the environment has access to use the KMS key given in environment creation.\n",
    "\n",
    "```\n",
    "\"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"Enable Managed kdb Insights Access\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"finspace.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"kms:Encrypt\",\n",
    "                \"kms:Decrypt\",\n",
    "                \"kms:GenerateDataKey\"\n",
    "            ],\n",
    "            \"Resource\": \"arn:aws:kms:us-east-1:ACCOUNT_ID:key/KEY_ID\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"aws:SourceAccount\": \"ACCOUNT_ID\"\n",
    "                },\n",
    "                \"ArnLike\": {\n",
    "                    \"aws:SourceArn\": \"arn:aws:finspace:us-east-1:ACCOUNT_ID:kxEnvironment/ENV_ID/*\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "   ]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d218119-1aa3-4485-a940-5dcde32b3fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp=get_kx_environment(client)\n",
    "\n",
    "print(\"Environment Information\")\n",
    "print(json.dumps(resp,sort_keys=True,indent=4,default=str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc29d8fc-c234-4c65-a633-bb9e16d6a772",
   "metadata": {},
   "source": [
    "## 1. Untar hdb.tar.gz\n",
    "hdb database will be found in hdb directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157b75f5-b582-490e-ae17-eb14eaafa21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf hdb.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fec4ecf-cba3-440f-a56e-4ec726c9f8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la hdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c8cbbe-654e-4385-92bc-5c7b80b5f0f3",
   "metadata": {},
   "source": [
    "# 2. Upload hdb data\n",
    "using aws cli, copy hdb to staging bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af169292-13fc-4b1b-863d-789d5a042d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "if AWS_ACCESS_KEY_ID is not None:\n",
    "    cp = f\"\"\"\n",
    "export AWS_ACCESS_KEY_ID={AWS_ACCESS_KEY_ID}\n",
    "export AWS_SECRET_ACCESS_KEY={AWS_SECRET_ACCESS_KEY}\n",
    "export AWS_SESSION_TOKEN={AWS_SESSION_TOKEN}\n",
    "\n",
    "aws s3 sync  --exclude .DS_Store {SOURCE_DATA_DIR} {S3_DEST}\n",
    "aws s3 ls {S3_DEST}\n",
    "\"\"\"\n",
    "else:\n",
    "    cp = f\"\"\"\n",
    "aws s3 sync  --exclude .DS_Store {SOURCE_DATA_DIR} {S3_DEST}\n",
    "aws s3 ls {S3_DEST}\n",
    "\"\"\"\n",
    "    \n",
    "# execute the S3 copy\n",
    "os.system(cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67476efe-d308-4158-9e24-8fbe71509f76",
   "metadata": {},
   "source": [
    "## 3. Create database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d00c39-876a-4bba-ab66-a3aa4fb9b65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume it exists\n",
    "create_db=False\n",
    "\n",
    "try:\n",
    "    resp = client.get_kx_database(environmentId=ENV_ID, databaseName=DB_NAME)\n",
    "    resp.pop('ResponseMetadata', None)\n",
    "except:\n",
    "    # does not exist, will create\n",
    "    create_db=True\n",
    "\n",
    "if create_db:\n",
    "    print(f\"CREATING Database: {DB_NAME}\")\n",
    "    resp = client.create_kx_database(environmentId=ENV_ID, databaseName=DB_NAME, description=\"Welcome kdb database\")\n",
    "    resp.pop('ResponseMetadata', None)\n",
    "\n",
    "    print(f\"CREATED Database: {DB_NAME}\")\n",
    "\n",
    "print(json.dumps(resp,sort_keys=True,indent=4,default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c84b3-2243-4abb-9032-8ae77a5e31f7",
   "metadata": {},
   "source": [
    "## 4. Add HDB data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b3a8df-c7ed-4837-99e3-07d95e7fbac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "changes=[]\n",
    "\n",
    "for f in os.listdir(\"hdb\"):\n",
    "    if os.path.isdir(f\"hdb/{f}\"):\n",
    "        changes.append( { 'changeType': 'PUT', 's3Path': f\"{S3_DEST}{f}/\", 'dbPath': f\"/{f}/\" } )\n",
    "    else:\n",
    "        changes.append( { 'changeType': 'PUT', 's3Path': f\"{S3_DEST}{f}\", 'dbPath': f\"/\" } )\n",
    "        \n",
    "resp = client.create_kx_changeset(environmentId=ENV_ID, databaseName=DB_NAME, changeRequests=changes)\n",
    "\n",
    "resp.pop('ResponseMetadata', None)\n",
    "changeset_id = resp['changesetId']\n",
    "\n",
    "print(\"Changeset...\")\n",
    "print(json.dumps(resp,sort_keys=True,indent=4,default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b344419-1261-43a3-89aa-f682ec54b0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_for_changeset_status(client, environmentId=ENV_ID, databaseName=DB_NAME, changesetId=changeset_id, show_wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1d2691-fe9a-47a7-8b1c-55ee1283e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_str = \"\"\n",
    "\n",
    "c_set_list = list_kx_changesets(client, environmentId=ENV_ID, databaseName=DB_NAME)\n",
    "\n",
    "if len(c_set_list) == 0:\n",
    "    note_str = \"<<Could not get changesets>>\"\n",
    "    \n",
    "print(100*\"=\")\n",
    "print(f\"Database: {DB_NAME}, Changesets: {len(c_set_list)} {note_str}\")\n",
    "print(100*\"=\")\n",
    "\n",
    "# sort by create time\n",
    "c_set_list = sorted(c_set_list, key=lambda d: d['createdTimestamp']) \n",
    "\n",
    "for c in c_set_list:\n",
    "    c_set_id = c['changesetId']\n",
    "    print(f\"  Changeset: {c_set_id}: Created: {c['createdTimestamp']} ({c['status']})\")\n",
    "    c_rqs = client.get_kx_changeset(environmentId=ENV_ID, databaseName=DB_NAME, changesetId=c_set_id)['changeRequests']\n",
    "\n",
    "    chs_pdf = pd.DataFrame.from_dict(c_rqs).style.hide(axis='index')\n",
    "    display(chs_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e42568f-5255-49d5-9bd9-0fd55298200d",
   "metadata": {},
   "source": [
    "## 5. Create a Cluster for the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89c57ce-896b-47d4-b71e-5984c5e5a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip the code\n",
    "#os.system(f\"zip -r -X {CODEBASE}.zip {CODEBASE} -x '*.ipynb_checkpoints*'\")\n",
    "os.system(f\"cd {CODEBASE}; zip -r -X ../{CODEBASE}.zip . -x '*.ipynb_checkpoints*';\")\n",
    "\n",
    "# copy code to S3\n",
    "\n",
    "if AWS_ACCESS_KEY_ID is not None:\n",
    "    cp = f\"\"\"\n",
    "export AWS_ACCESS_KEY_ID={AWS_ACCESS_KEY_ID}\n",
    "export AWS_SECRET_ACCESS_KEY={AWS_SECRET_ACCESS_KEY}\n",
    "export AWS_SESSION_TOKEN={AWS_SESSION_TOKEN}\n",
    "\n",
    "aws s3 cp  --exclude .DS_Store {CODEBASE}.zip s3://{S3_BUCKET}/code/{CODEBASE}.zip\n",
    "aws s3 ls s3://{S3_BUCKET}/code/\n",
    "\"\"\"\n",
    "else:\n",
    "    cp = f\"\"\"\n",
    "aws s3 cp  --exclude .DS_Store {CODEBASE}.zip s3://{S3_BUCKET}/code/{CODEBASE}.zip\n",
    "aws s3 ls s3://{S3_BUCKET}/code/\n",
    "\"\"\"\n",
    "    \n",
    "# execute the S3 copy\n",
    "os.system(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36142f08-5a68-4c22-993e-e169628133e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Creating: {CLUSTER_NAME}\")\n",
    "\n",
    "resp = client.create_kx_cluster(\n",
    "    environmentId=ENV_ID, \n",
    "    clusterName=CLUSTER_NAME,\n",
    "    clusterDescription=f\"Demo Cluster for database {DB_NAME}\",\n",
    "    clusterType='HDB',\n",
    "    releaseLabel = '1.0',\n",
    "    capacityConfiguration={ \"nodeType\": \"kx.s.xlarge\", \"nodeCount\": NODE_COUNT },\n",
    "    databases=[{ \n",
    "        'databaseName': DB_NAME, \n",
    "        'cacheConfigurations': [\n",
    "            {'dbPaths':['/'], 'cacheType': 'CACHE_1000' }\n",
    "        ] \n",
    "    }],\n",
    "    cacheStorageConfigurations=[{ 'type': 'CACHE_1000', 'size': CACHE_SIZE }],\n",
    "    azMode=AZ_MODE,\n",
    "    availabilityZoneId=AZ_ID,\n",
    "    vpcConfiguration={ \n",
    "        'vpcId': VPC_ID,\n",
    "        'securityGroupIds': SECURITY_GROUPS,\n",
    "        'subnetIds': SUBNET_IDS,\n",
    "        'ipAddressType': 'IP_V4' },\n",
    "    code={ 's3Bucket': S3_BUCKET, 's3Key': CODE_PATH },\n",
    "#    initializationScript=f\"{CODEBASE}/init.q\",\n",
    "    initializationScript=f\"init.q\",\n",
    "    commandLineArguments=[\n",
    "        {'key': 's', 'value': '4'}, \n",
    "        {'key': 'dbname', 'value': DB_NAME}, \n",
    "#        {'key': 'codebase', 'value': CODEBASE}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32bdf1d-0f12-4d0e-8ac8-0c6a691d1896",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c21dbb8-9878-441f-997b-f27164e1e6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_for_cluster_status(client, environmentId=ENV_ID, clusterName=CLUSTER_NAME, show_wait=False)\n",
    "print()\n",
    "print(\"** DONE **\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1a5cac-c0f6-4478-8f67-0c1060fe986a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Get the connectionString\n",
    "This assumes that the IAM role exists and the user (KDB_USERNAME) have beed already added as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477af774-ee69-4cd8-bb79-0bb983b6fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    resp = client.get_kx_cluster(environmentId=ENV_ID, clusterName=CLUSTER_NAME)\n",
    "except client.exceptions.ResourceNotFoundException:\n",
    "    print(F\"Cluster: {CLUSTER_NAME} did not create\")\n",
    "    \n",
    "if resp['ResponseMetadata']['HTTPStatusCode'] != 200:\n",
    "    sys.stderr.write(\"Error:\\n {resp}\")\n",
    "else:\n",
    "    resp.pop('ResponseMetadata', None)\n",
    "\n",
    "kx_cluster = resp\n",
    "\n",
    "print(\"Cluster: \"+(\"-\"*80))\n",
    "print(json.dumps(kx_cluster, sort_keys=True, indent=4, default=str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7747eeb0-e0c4-43b0-8208-336fb3ea6286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give permissions time to propogate after cluster creation....\n",
    "time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c63c186-d837-4185-9280-2a486425f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_str = get_kx_connection_string(client, environmentId=ENV_ID, clusterName=CLUSTER_NAME, userName=KDB_USERNAME, boto_session=session)\n",
    "\n",
    "print (\"\")\n",
    "print(\"Copy into q: \"+(\"-\"*80))\n",
    "print(f\"\"\"\n",
    "/ Cluster: {CLUSTER_NAME}\n",
    "hdb_conn:\"{conn_str}\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f67a2fe-d592-43b8-868a-8219e603d77f",
   "metadata": {},
   "source": [
    "## 7. Query Cluster using PyKX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d3ef3-6a39-4390-aeb4-723dcb5166d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the HDB\n",
    "hdb = get_pykx_connection(client, \n",
    "                          environmentId=ENV_ID, clusterName=CLUSTER_NAME, \n",
    "                          userName=KDB_USERNAME, boto_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a4bdb0-0e77-4c2a-aade-3d4a112013cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tables\n",
    "tables = hdb(\"tables[]\").py()\n",
    "print(f\"Tables ({len(tables)}): {tables}\")\n",
    "\n",
    "# Schema\n",
    "schema_pdf = hdb(\"meta `example\").pd()\n",
    "display(schema_pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15469493-9105-480f-9a16-8a18eda7bc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Query, uses function from lib\n",
    "res_table = hdb(\"select counts:count i, avg_num: avg number, avg_sq_num: avg sq number by date from example\").pd()\n",
    "display(res_table)\n",
    "\n",
    "# Number of Rows in Table\n",
    "rows = hdb(\"count example\").py()\n",
    "print(f\"Rows: {rows:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec5839-e519-42d2-ab62-a524cee0bdfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941c540a-f4ed-46a1-a7ba-7e125b72501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Deletion\n",
    "# ------------------------------------------------------------\n",
    "db_list = list_kx_databases(client, environmentId=ENV_ID)\n",
    "db_list\n",
    "\n",
    "db_pdf = pd.DataFrame.from_dict(db_list).style.hide(axis='index')\n",
    "display(db_pdf)\n",
    "print(\"\")\n",
    "\n",
    "cluster_deleted=False\n",
    "\n",
    "if DELETE_CLUSTER:   \n",
    "    # list all clusters\n",
    "    resp=client.get_kx_cluster(environmentId=ENV_ID, clusterName=CLUSTER_NAME)\n",
    "    \n",
    "    if resp['ResponseMetadata']['HTTPStatusCode'] != 200:\n",
    "        sys.stderr.write(\"Error:\\n {resp}\")\n",
    "    else:\n",
    "        resp.pop('ResponseMetadata', None)\n",
    "\n",
    "    if resp['status'] != 'DELETING':\n",
    "        try:\n",
    "            resp = client.delete_kx_cluster(environmentId=ENV_ID, clusterName=CLUSTER_NAME)\n",
    "            if resp['ResponseMetadata']['HTTPStatusCode'] != 200:\n",
    "                sys.stderr.write(\"Error:\\n {resp}\")\n",
    "            else:\n",
    "                resp.pop('ResponseMetadata', None)\n",
    "        except Exception as e: \n",
    "            sys.stderr.write(f\"Error deleting cluster: {CLUSTER_NAME}\\n{e}\")\n",
    "            cluster_deleted = False\n",
    "\n",
    "    try:\n",
    "        wait_for_cluster_status(client, environmentId=ENV_ID, clusterName=CLUSTER_NAME, status='DELETED', show_wait=False)\n",
    "        print()\n",
    "        print(\"** DONE **\")\n",
    "\n",
    "        cluster_deleted = True\n",
    "    except client.exceptions.ResourceNotFoundException:\n",
    "        cluster_deleted = True\n",
    "else:\n",
    "    print(f\"DELETE_CLUSTER: {DELETE_CLUSTER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da3a6c-c7ba-46f1-8908-198f36b3349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database Deletion\n",
    "# Requires cluster to have been deleted\n",
    "if DELETE_DATABASE:\n",
    "    if cluster_deleted:\n",
    "        # if the database exists, delete it\n",
    "        if has_database(client, environmentId=ENV_ID, databaseName=DB_NAME):\n",
    "            try:\n",
    "                resp = client.delete_kx_database(environmentId=ENV_ID, databaseName=DB_NAME)\n",
    "                if resp['ResponseMetadata']['HTTPStatusCode'] != 200:\n",
    "                    sys.stderr.write(\"Error:\\n {resp}\")\n",
    "                else:\n",
    "                    resp.pop('ResponseMetadata', None)\n",
    "\n",
    "                resp\n",
    "            except Exception as e: \n",
    "                sys.stderr.write(f\"Error: \\n{e}\")\n",
    "        else:\n",
    "            print(f\"Database already deleted: {DB_NAME} \")\n",
    "    else:\n",
    "        print(f\"Cluster deleted? {cluster_deleted}, will not delete database if cluster not deleted\")\n",
    "else:\n",
    "    print(f\"DELETE_DATABASE: {DELETE_DATABASE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2346146-b86a-4d95-9f82-5b4e4705acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_list = list_kx_databases(client, environmentId=ENV_ID)\n",
    "db_list=sorted(db_list, key=lambda d: d['databaseName']) \n",
    "\n",
    "db_pdf = pd.DataFrame.from_dict(db_list).style.hide(axis='index')\n",
    "display(db_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae3d31a-c70d-4a4c-935f-5d86f700a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = get_clusters(client, environmentId=ENV_ID)\n",
    "\n",
    "display(cdf)\n",
    "\n",
    "print( f\"Last Run: {datetime.datetime.now()}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe3a21-1bf9-47ba-b162-70ab5445b44f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
