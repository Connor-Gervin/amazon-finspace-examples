{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47bb4665-c0eb-4f58-9749-64e13a1682a7",
   "metadata": {},
   "source": [
    "# Processing TAQ Data\n",
    "Example of how to process a collection of csv files, that are compressed, and arranged in a bespoke directory structure. The structure is **ROOT**/**DATE**/**A-Z First Letter of Ticker**/**TICKER**.csv.gz. All files come from and S3 bucket.\n",
    "\n",
    "## Algoseek LLC Data\n",
    "Trade and Quote data has been provided by [AlgoSeek LLC](https://www.algoseek.com/), you can learn more about their data offerings from their home page.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b0c521d-ddc4-4c71-b83d-6f655103c51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import boto3\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "from env import *\n",
    "import pykx as kx\n",
    "import awswrangler as wr\n",
    "\n",
    "from managed_kx import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a91712-3f1d-4041-86de-c70543bfb0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pykx.Identity(pykx.q('::'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------------------------------\n",
    "DB_NAME=\"DEMO_DB\"\n",
    "DBVIEW_NAME=f\"{DB_NAME}_VIEW\"\n",
    "SCALING_GROUP_NAME=\"DEMO_SCALING_GROUP\"\n",
    "VOLUME_NAME=\"DEMO_SHARED_VOLUME\"\n",
    "CODEBASE=\"demo\"\n",
    "CLUSTER_NAME=\"demo_csv_cluster\"\n",
    "\n",
    "HDB_CLUSTER_NAME=\"demo_hdb_cluster\"\n",
    "\n",
    "# S3 Destinations\n",
    "S3_CODE_PATH=\"code\"\n",
    "S3_DATA_PATH=\"data\"\n",
    "SOURCE_DATA_DIR=\"demo\"\n",
    "# ----------------------------------------------------------------\n",
    "WORKING_DIR=f\"/opt/kx/app/shared/{VOLUME_NAME}/{CLUSTER_NAME}\"\n",
    "\n",
    "LOCAL_DATA_HOME=\"algoseek-marketdata/us-equity-taq-faang\"\n",
    "S3_DATA_HOME=\"s3://kdb-demo-829845998889-kms/algoseek-marketdata/us-equity-taq-faang\"\n",
    "\n",
    "# Two days supplied in Tarball\n",
    "DATE=datetime.date(2021,1,4)\n",
    "#DATE=datetime.date(2021,1,5)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# set q console width and height\n",
    "kx.q(\"\\c 200 200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22dd100d-d0aa-4f13-a305-502a86041b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Defaults ...\n"
     ]
    }
   ],
   "source": [
    "# Create AWS Session for working with FinSpace service\n",
    "session=None\n",
    "\n",
    "try:\n",
    "    # aws: use ada for credentials\n",
    "    os.system([\"which\", \"ada\"])\n",
    "    os.system(f\"ada credentials update --account={ACCOUNT_ID} --provider=isengard --role=Admin --once\")\n",
    "except: \n",
    "    None\n",
    "\n",
    "if AWS_ACCESS_KEY_ID is None:\n",
    "    print(\"Using Defaults ...\")\n",
    "    # create AWS session: using access variables\n",
    "    session = boto3.Session()\n",
    "else:\n",
    "    print(\"Using variables ...\")\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "        aws_session_token=AWS_SESSION_TOKEN\n",
    "    )\n",
    "\n",
    "# create finspace client\n",
    "client = session.client(service_name='finspace', endpoint_url=ENDPOINT_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2e3baf-910f-4361-a5ac-272f8aca7946",
   "metadata": {},
   "source": [
    "# Stage TAQ Data to S3\n",
    "Copy the supplied sample TAQ data to an S3 bucket. Then the data will be processed by GP cluster from the S3 location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9685e738-4608-446b-a21d-4f8861eab0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf algoseek-marketdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ce2a015-fdba-4834-a118-4dfa7ace5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xzf algoseek-marketdata.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce0a5eee-b441-48da-825e-ee19d579190b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: algoseek-marketdata/us-equity-taq-faang/2021/20210104/A/AMZN.csv.gz to s3://kdb-demo-829845998889-kms/algoseek-marketdata/us-equity-taq-faang/2021/20210104/A/AMZN.csv.gz\n",
      "upload: algoseek-marketdata/us-equity-taq-faang/2021/20210104/F/FB.csv.gz to s3://kdb-demo-829845998889-kms/algoseek-marketdata/us-equity-taq-faang/2021/20210104/F/FB.csv.gz\n",
      "upload: algoseek-marketdata/us-equity-taq-faang/2021/20210104/G/GOOG.csv.gz to s3://kdb-demo-829845998889-kms/algoseek-marketdata/us-equity-taq-faang/2021/20210104/G/GOOG.csv.gz\n",
      "upload: algoseek-marketdata/us-equity-taq-faang/2021/20210104/N/NFLX.csv.gz to s3://kdb-demo-829845998889-kms/algoseek-marketdata/us-equity-taq-faang/2021/20210104/N/NFLX.csv.gz\n",
      "upload: algoseek-marketdata/us-equity-taq-faang/2021/20210104/A/AAPL.csv.gz to s3://kdb-demo-829845998889-kms/algoseek-marketdata/us-equity-taq-faang/2021/20210104/A/AAPL.csv.gz\n",
      "upload: algoseek-marketdata/us-equity-taq-faang/2021/20210105/A/AAPL.csv.gz to s3://kdb-demo-829845998889-kms/algoseek-marketdata/us-equity-taq-faang/2021/20210105/A/AAPL.csv.gz\n",
      "upload: algoseek-marketdata/us-equity-taq-faang/2021/20210105/A/AMZN.csv.gz to s3://kdb-demo-829845998889-kms/algoseek-marketdata/us-equity-taq-faang/2021/20210105/A/AMZN.csv.gz\n",
      "upload: algoseek-marketdata/us-equity-taq-faang/2021/20210105/N/NFLX.csv.gz to s3://kdb-demo-829845998889-kms/algoseek-marketdata/us-equity-taq-faang/2021/20210105/N/NFLX.csv.gz\n",
      "upload: algoseek-marketdata/us-equity-taq-faang/2021/20210105/G/GOOG.csv.gz to s3://kdb-demo-829845998889-kms/algoseek-marketdata/us-equity-taq-faang/2021/20210105/G/GOOG.csv.gz\n",
      "upload: algoseek-marketdata/us-equity-taq-faang/2021/20210105/F/FB.csv.gz to s3://kdb-demo-829845998889-kms/algoseek-marketdata/us-equity-taq-faang/2021/20210105/F/FB.csv.gz\n",
      "                           PRE us-equity-taq-faang/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stage TAQ data to S3\n",
    "if AWS_ACCESS_KEY_ID is not None:\n",
    "    cp = f\"\"\"\n",
    "export AWS_ACCESS_KEY_ID={AWS_ACCESS_KEY_ID}\n",
    "export AWS_SECRET_ACCESS_KEY={AWS_SECRET_ACCESS_KEY}\n",
    "export AWS_SESSION_TOKEN={AWS_SESSION_TOKEN}\n",
    "\n",
    "aws s3 rm --recursive {S3_DATA_HOME}\n",
    "aws s3 sync --exclude .DS_Store {LOCAL_DATA_HOME} {S3_DATA_HOME}\n",
    "aws s3 ls {S3_DATA_HOME}\n",
    "\"\"\"\n",
    "else:\n",
    "    cp = f\"\"\"\n",
    "aws s3 rm --recursive {S3_DATA_HOME}\n",
    "aws s3 sync --exclude .DS_Store {LOCAL_DATA_HOME} {S3_DATA_HOME}\n",
    "aws s3 ls {S3_DATA_HOME}\n",
    "\"\"\"\n",
    "    \n",
    "# execute the S3 copy\n",
    "os.system(cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1709c470-bd30-4a16-8059-dc72be6096f4",
   "metadata": {},
   "source": [
    "# Before State of HDB\n",
    "This is the state/contents of the HDB before we process the CSV files as new date. There will be a table (taq) with no data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43745eaf-db1b-4613-a75f-a8e25c3c7b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Tables and Counts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>taq</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "pykx.Dictionary(pykx.q('taq| 0'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Table: taq\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>f</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>\"d\"</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <td>\"s\"</td>\n",
       "      <td></td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <td>\"n\"</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EventType</th>\n",
       "      <td>\"s\"</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>\"f\"</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quantity</th>\n",
       "      <td>\"j\"</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exchange</th>\n",
       "      <td>\"s\"</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conditions</th>\n",
       "      <td>\"s\"</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "pykx.KeyedTable(pykx.q('\n",
       "c         | t f a\n",
       "----------| -----\n",
       "date      | d    \n",
       "Ticker    | s   p\n",
       "Timestamp | n    \n",
       "EventType | s    \n",
       "Price     | f    \n",
       "Quantity  | j    \n",
       "Exchange  | s    \n",
       "Conditions| s    \n",
       "'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "pykx.Table(pykx.q('\n",
       "date Ticker Timestamp EventType Price Quantity Exchange Conditions\n",
       "------------------------------------------------------------------\n",
       "'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "pykx.Table(pykx.q('\n",
       "date Ticker Timestamp EventType Price Quantity Exchange Conditions\n",
       "------------------------------------------------------------------\n",
       "'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "pykx.KeyedTable(pykx.q('\n",
       "date| rows\n",
       "----| ----\n",
       "'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "pykx.KeyedTable(pykx.q('\n",
       "date Ticker| rows\n",
       "-----------| ----\n",
       "'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query the HDB for before state\n",
    "hdb = get_pykx_connection(client, \n",
    "                          environmentId=ENV_ID, clusterName=HDB_CLUSTER_NAME, \n",
    "                          userName=KDB_USERNAME, boto_session=session)\n",
    "\n",
    "tables = hdb(\"tables[]\").py()\n",
    "\n",
    "# inventory of tables in the database and rows in each\n",
    "print(80*'=')\n",
    "print(\"Tables and Counts\")\n",
    "display( hdb(\"tables[]!count each value each tables[]\") )\n",
    "\n",
    "# For each table: schema, and samples and counts\n",
    "for t in tables:\n",
    "    print(80*'=')\n",
    "    print (f'Table: {t}')\n",
    "    print(80*'-')\n",
    "    display( hdb(f\"meta {t}\") )\n",
    "    display( hdb(f\"select from {t} where date = min date, i<3\") )\n",
    "    display( hdb(f\"select from {t} where date = max date, i<3\") )\n",
    "    display( hdb(f\"select rows:count i by date from {t}\") )\n",
    "    display( hdb(f\"select rows:count i by date,Ticker from {t}\") )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6787c3f0-f396-4683-9edc-f86de0786844",
   "metadata": {},
   "source": [
    "# Process from Cluster\n",
    "Connect to the GP cluster and use it to process the list of external S3 files (csv.gz format). The list of S3 files to process will be given to the cluster and processed with the process_s3_csvgz function in q provided by this notebook.\n",
    "\n",
    "## parse_csvgz\n",
    "This function will process a a local file (csv.gz) into an in-memory table taking a local file and schema as arguments.\n",
    "\n",
    "## process_s3_csvgz\n",
    "This function will process an S3 based file (csv.gz) into an in-memory table, levering the parse_csvgz function. The function will copy the S3 file to a working directory (arguments of function), process it with parse_csvgz and clean up after itself by deleting the copied file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "549ebbba-1412-4279-860a-d7c84bc6e0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = get_pykx_connection(client, \n",
    "                        environmentId=ENV_ID, clusterName=CLUSTER_NAME, \n",
    "                        userName=KDB_USERNAME, boto_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0f22e45-f22e-412a-a4ba-6afac5be2405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pykx.Identity(pykx.q('::'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define functions on cluster\n",
    "gp('''\n",
    "diR:{$[11h=type d:key x;raze x,.z.s each` sv/:x,/:d;d]};\n",
    "nuke:hdel each desc diR@;\n",
    "\n",
    "parse_csvgz:{[schema;file] (schema;enlist csv) 0: .Q.gz \"c\"$read1 hsym `$ string file};\n",
    "\n",
    "process_s3_csvgz:{[schema;work_dir;s3_object]\n",
    "    r:.aws.s3.get_object[s3_object;work_dir];\n",
    "    raze {t:parse_csvgz[x;`$y]; hdel hsym`$y; t}[schema] each r`containerFileDestinationPath\n",
    "};\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8797df67-5cb5-4a05-905d-020f2cb96d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server Tables: ['taq']\n",
      "Slave Threads: 4\n",
      "S3 Objects: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['s3://kdb-demo-829845998889-kms/algoseek-marketdata/us-equity-taq-faang/2021/20210105/A/AAPL.csv.gz',\n",
       " 's3://kdb-demo-829845998889-kms/algoseek-marketdata/us-equity-taq-faang/2021/20210105/A/AMZN.csv.gz',\n",
       " 's3://kdb-demo-829845998889-kms/algoseek-marketdata/us-equity-taq-faang/2021/20210105/F/FB.csv.gz']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# search for S3 objects\n",
    "s3_search=f'{S3_DATA_HOME}/{DATE.year}/{DATE.strftime(\"%Y%m%d\")}/*/*.csv.gz'\n",
    "\n",
    "# Get list of S3 objects that will be processed into the table\n",
    "slist = wr.s3.list_objects(s3_search)\n",
    "\n",
    "# Tables in memory\n",
    "print( f\"Server Tables: {gp('tables[]').py()}\" )\n",
    "\n",
    "# Number of available slave threads (used by peach)\n",
    "s=gp('\\s').py()\n",
    "print( f\"Slave Threads: {s}\" )\n",
    "\n",
    "# Number of files to be processed\n",
    "print(f\"S3 Objects: {len(slist)}\")\n",
    "display(slist[:3])\n",
    "# STEP if list is empty\n",
    "if (len(slist) == 0):\n",
    "    raise SystemExit(f\"Stop no files: {s3_search}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0db0199f-819f-461a-9b00-69952fccce6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pykx.Identity(pykx.q('::'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send slist to cluster\n",
    "gp['slist'] = slist\n",
    "\n",
    "# send working directory to cluster, this is where each S3 object will be copied to before processing into a table\n",
    "gp['wd'] = WORKING_DIR\n",
    "\n",
    "# Process the list of S3 files into one table (df) and Delete the Date column (this will be the partition as date in schema)\n",
    "gp('''\n",
    "taq:raze{.Q.gc[]; process_s3_csvgz [x; y; z]}[\"DNSSFJSS\";wd] peach slist;\n",
    "\n",
    "delete Date from `taq;\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "062cd80c-1ded-4f98-b29d-fb28fddb3bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 days 04:00:00.074828586</td>\n",
       "      <td>TRADE</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>130.07</td>\n",
       "      <td>639</td>\n",
       "      <td>ARCA</td>\n",
       "      <td>20000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 days 04:00:00.077890184</td>\n",
       "      <td>QUOTE BID</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>120.00</td>\n",
       "      <td>100</td>\n",
       "      <td>ARCA</td>\n",
       "      <td>00000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 days 04:00:00.077890184</td>\n",
       "      <td>QUOTE ASK</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>ARCA</td>\n",
       "      <td>00000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Timestamp  EventType Ticker   Price  Quantity Exchange  \\\n",
       "0 0 days 04:00:00.074828586      TRADE   AAPL  130.07       639     ARCA   \n",
       "1 0 days 04:00:00.077890184  QUOTE BID   AAPL  120.00       100     ARCA   \n",
       "2 0 days 04:00:00.077890184  QUOTE ASK   AAPL    0.00         0     ARCA   \n",
       "\n",
       "  Conditions  \n",
       "0   20000401  \n",
       "1   00000001  \n",
       "2   00000001  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 days 19:59:29.696901119</td>\n",
       "      <td>TRADE</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>521.00</td>\n",
       "      <td>1</td>\n",
       "      <td>ARCA</td>\n",
       "      <td>80000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 days 19:59:44.493541009</td>\n",
       "      <td>QUOTE BID NB</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>520.00</td>\n",
       "      <td>300</td>\n",
       "      <td>ARCA</td>\n",
       "      <td>00000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 days 19:59:44.493541009</td>\n",
       "      <td>QUOTE ASK NB</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>521.66</td>\n",
       "      <td>200</td>\n",
       "      <td>ARCA</td>\n",
       "      <td>00000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Timestamp     EventType Ticker   Price  Quantity Exchange  \\\n",
       "0 0 days 19:59:29.696901119         TRADE   NFLX  521.00         1     ARCA   \n",
       "1 0 days 19:59:44.493541009  QUOTE BID NB   NFLX  520.00       300     ARCA   \n",
       "2 0 days 19:59:44.493541009  QUOTE ASK NB   NFLX  521.66       200     ARCA   \n",
       "\n",
       "  Conditions  \n",
       "0   80000401  \n",
       "1   00000001  \n",
       "2   00000001  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows: 27,360,751\n"
     ]
    }
   ],
   "source": [
    "# Show what is in the table, sample head and tail 5 rows...\n",
    "display( gp('select [3] from taq').pd() )\n",
    "display( gp('select [-3] from taq').pd() )\n",
    "print()\n",
    "\n",
    "# Total number of rows\n",
    "print( f\"Rows: {gp('count taq').py():,}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa9c0d2-2991-4209-8778-29f6cd80097e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# In Memory Contents\n",
    "We now have two in memory tables (df1 and df2). One (df1) was sourced from a local csv file, and the other (df2) was sourced from a file on S3 (which was put in S3 from this location)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01a8c602-fda9-4a28-b9e2-98e6f15fd496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables and Counts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>taq</th>\n",
       "      <td>27360751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "pykx.Dictionary(pykx.q('taq| 27360751'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tables we have now\n",
    "print(\"Tables and Counts\")\n",
    "display( gp(\"tables[]!count each value each tables[]\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc86f3c5-a494-489a-969a-7bfdce63a3b3",
   "metadata": {},
   "source": [
    "# Add to Database: Create the Changeset\n",
    "Will create a changeset for the database that includes the two tables (df1 and df2) and will create a changeset as a new date partition of the database with the in-memory tables splayed to disk for today's date.\n",
    "\n",
    "## q Code\n",
    "Code run on the cluster to save in-memory tables to disk and then add those files to the maanged database. This adds the two in memory tables (df1 and df2) to the Managed Database under a new date partition.\n",
    "\n",
    "```\n",
    "diR:{$[11h=type d:key x;raze x,.z.s each` sv/:x,/:d;d]};\n",
    "nuke:hdel each desc diR@;\n",
    "\n",
    "saveTables:{[db;path;d]\n",
    "    .aws.get_latest_sym_file[db;path];\n",
    "    t:tables`.;\n",
    "    t@:where `g=attr each t@\\:`sym;\n",
    "    {.Q.dpft[hsym`$x;y;`sym;z]}[path;d] each tables`.;\n",
    "\n",
    "    dt:string d;\n",
    "    dict:flip`input_path`database_path`change_type!(\n",
    "        (`$path,dt;`$path,\"sym\");\n",
    "        (`$\"/\",dt,\"/\";`$\"/\");`PUT`PUT);\n",
    "    cid:.aws.create_changeset[db;dict];\n",
    "    \n",
    "    nuke hsym`$path,string[d];\n",
    "    hdel hsym`$path,\"sym\";\n",
    "\n",
    "    @[;`sym;`g#] each t;\n",
    "    .Q.gc[];\n",
    "\n",
    "    cid\n",
    "};\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6b9e162-c499-432b-8ba5-078449eed310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pykx.Identity(pykx.q('::'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define some functions\n",
    "\n",
    "# diR: gets listing of files in directory\n",
    "# nuke: deletes directory and its contents\n",
    "# saveTables: Saves all in-memory tables that have the group attribute on a sym column, updating the sym file as well.\n",
    "\n",
    "gp(\"\"\"\n",
    "diR:{$[11h=type d:key x;raze x,.z.s each` sv/:x,/:d;d]};\n",
    "nuke:hdel each desc diR@;\n",
    "\n",
    "saveTables:{[db;path;d]\n",
    "    .aws.get_latest_sym_file[db;path];\n",
    "    t:tables`.;\n",
    "    t@:where `g=attr each t@\\:`Ticker;\n",
    "    {.Q.dpft[hsym`$x;y;`Ticker;z]}[path;d] each tables`.;\n",
    "\n",
    "    dt:string d;\n",
    "    dict:flip`input_path`database_path`change_type!(\n",
    "        (`$path,dt;`$path,\"sym\");\n",
    "        (`$\"/\",dt,\"/\";`$\"/\");`PUT`PUT);\n",
    "    cid:.aws.create_changeset[db;dict];\n",
    "    \n",
    "    nuke hsym`$path,string[d];\n",
    "    hdel hsym`$path,\"sym\";\n",
    "\n",
    "    @[;`Ticker;`g#] each t;\n",
    "    .Q.gc[];\n",
    "\n",
    "    cid\n",
    "};\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66f4f117-18a0-4731-af43-48f4a1f60837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YMesyucSrX60IrXKdemSzA'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tables will be added as a new date partition\n",
    "gp[\"dt\"] = DATE\n",
    "\n",
    "# save tables and collect the changeset ID\n",
    "cmd = f'cid:saveTables[\"{DB_NAME}\";\"{WORKING_DIR}/\";dt]'\n",
    "gp(cmd)\n",
    "\n",
    "# Newly created changset ID\n",
    "changeset_id = str(gp(\"cid`id\"))\n",
    "display( changeset_id )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edd05f59-9b88-433b-91ac-0fa01d0c5813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status is IN_PROGRESS, total wait 0:00:00, waiting 10 sec ...\n",
      "Status is IN_PROGRESS, total wait 0:00:10, waiting 10 sec ...\n",
      "Status is IN_PROGRESS, total wait 0:00:20, waiting 10 sec ...\n",
      "Status is IN_PROGRESS, total wait 0:00:30, waiting 10 sec ...\n",
      "**Done**\n"
     ]
    }
   ],
   "source": [
    "# Wait for the changeset to ingest\n",
    "wait_for_changeset_status(client, environmentId=ENV_ID, databaseName=DB_NAME, changesetId=changeset_id, show_wait=True)\n",
    "print(\"**Done**\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23816e7-0b6b-4ca0-b2f9-3f5dd91a4a32",
   "metadata": {},
   "source": [
    "# Update the HDB\n",
    "Now that the database has been populated with new data, update the HDB's view to reflect the latest changeset_id and query its contents to confirm the data from the CSVs are now in the tables of the database HDB is serving up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9f88df6-765b-4319-b7bb-f375707077fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataview DEMO_DB_VIEW exists but needs updating, updating...\n"
     ]
    }
   ],
   "source": [
    "# get the list of changesets in the database\n",
    "c_set_list = list_kx_changesets(client, environmentId=ENV_ID, databaseName=DB_NAME)\n",
    "\n",
    "if len(c_set_list) != 0:\n",
    "    # sort by create time\n",
    "    c_set_list = sorted(c_set_list, key=lambda d: d['createdTimestamp']) \n",
    "    latest_changeset = c_set_list[-1]['changesetId']\n",
    "\n",
    "    # Check if dataview already exists and is set to the requested changeset_id\n",
    "    resp = get_kx_dataview(client=client, environmentId=ENV_ID, databaseName=DB_NAME, dataviewName=DBVIEW_NAME)\n",
    "\n",
    "    if resp is None:\n",
    "        resp = client.create_kx_dataview(\n",
    "            environmentId = ENV_ID, \n",
    "            databaseName=DB_NAME, \n",
    "            dataviewName=DBVIEW_NAME,\n",
    "            azMode='SINGLE',\n",
    "            availabilityZoneId=AZ_ID,\n",
    "            changesetId=latest_changeset, # latest changeset_id\n",
    "            segmentConfigurations=[\n",
    "                { \n",
    "                    'volumeName': VOLUME_NAME,\n",
    "                    'dbPaths': ['/*'],  # cache all of database\n",
    "    #                \"onDemand\": True,   # cache data onDemand (on read) else will ensure all is cached\n",
    "                }\n",
    "            ],\n",
    "    #        readWrite=True,\n",
    "            autoUpdate=False,\n",
    "            description = f'Dataview of database'\n",
    "        )\n",
    "    elif resp['changesetId'] != latest_changeset:\n",
    "        print(f\"Dataview {DBVIEW_NAME} exists but needs updating, updating...\")\n",
    "        resp = client.update_kx_dataview(environmentId=ENV_ID, \n",
    "            databaseName=DB_NAME, \n",
    "            dataviewName=DBVIEW_NAME, \n",
    "            changesetId=latest_changeset, \n",
    "            segmentConfigurations=[\n",
    "                {'dbPaths': ['/*'], 'volumeName': VOLUME_NAME}\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Dataview {DBVIEW_NAME} exists with current changeset: {latest_changeset}\")\n",
    "    \n",
    "else:\n",
    "    # no changesets, do NOT create view\n",
    "    print(f\"No changeset in database: {DB_NAME}, Dataview {DBVIEW_NAME} not created\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c561d456-d562-4135-9a33-b0a63863c3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataview: DEMO_DB_VIEW status is UPDATING, total wait 0:00:00, waiting 30 sec ...\n",
      "Dataview: DEMO_DB_VIEW status is UPDATING, total wait 0:00:30, waiting 30 sec ...\n",
      "Dataview: DEMO_DB_VIEW status is UPDATING, total wait 0:01:00, waiting 30 sec ...\n",
      "Dataview: DEMO_DB_VIEW status is UPDATING, total wait 0:01:30, waiting 30 sec ...\n",
      "Dataview: DEMO_DB_VIEW status is UPDATING, total wait 0:02:00, waiting 30 sec ...\n",
      "Dataview: DEMO_DB_VIEW status is UPDATING, total wait 0:02:30, waiting 30 sec ...\n",
      "Dataview: DEMO_DB_VIEW status is UPDATING, total wait 0:03:00, waiting 30 sec ...\n",
      "Dataview: DEMO_DB_VIEW status is UPDATING, total wait 0:03:30, waiting 30 sec ...\n",
      "Dataview: DEMO_DB_VIEW status is UPDATING, total wait 0:04:00, waiting 30 sec ...\n",
      "Dataview: DEMO_DB_VIEW status is UPDATING, total wait 0:04:30, waiting 30 sec ...\n",
      "Dataview: DEMO_DB_VIEW status is UPDATING, total wait 0:05:00, waiting 30 sec ...\n",
      "Dataview: DEMO_DB_VIEW status is UPDATING, total wait 0:05:30, waiting 30 sec ...\n",
      "Dataview: DEMO_DB_VIEW status is now ACTIVE, total wait 0:06:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'databaseName': 'DEMO_DB',\n",
       " 'dataviewName': 'DEMO_DB_VIEW',\n",
       " 'azMode': 'SINGLE',\n",
       " 'availabilityZoneId': 'use1-az6',\n",
       " 'changesetId': 'YMesyucSrX60IrXKdemSzA',\n",
       " 'segmentConfigurations': [{'dbPaths': ['/*'],\n",
       "   'volumeName': 'DEMO_SHARED_VOLUME',\n",
       "   'onDemand': False}],\n",
       " 'activeVersions': [{'changesetId': 'YMesyucSrX60IrXKdemSzA',\n",
       "   'segmentConfigurations': [{'dbPaths': ['/*'],\n",
       "     'volumeName': 'DEMO_SHARED_VOLUME',\n",
       "     'onDemand': False}],\n",
       "   'attachedClusters': [],\n",
       "   'createdTimestamp': datetime.datetime(2024, 5, 8, 19, 3, 5, 463000, tzinfo=tzlocal()),\n",
       "   'versionId': 'gMesyz37zA6bcFdXH7P71w'},\n",
       "  {'changesetId': 'EMesq6rn0bqzz6vvXlf5Kw',\n",
       "   'segmentConfigurations': [{'dbPaths': ['/*'],\n",
       "     'volumeName': 'DEMO_SHARED_VOLUME',\n",
       "     'onDemand': False}],\n",
       "   'attachedClusters': ['demo_csv_cluster', 'demo_hdb_cluster'],\n",
       "   'createdTimestamp': datetime.datetime(2024, 5, 8, 17, 55, 2, 963000, tzinfo=tzlocal()),\n",
       "   'versionId': 'FMesrBhZzqITXJkjmRJR7w'}],\n",
       " 'description': 'Dataview of database',\n",
       " 'autoUpdate': False,\n",
       " 'readWrite': False,\n",
       " 'environmentId': 'jlcenjvtkgzrdek2qqv7ic',\n",
       " 'createdTimestamp': datetime.datetime(2024, 5, 8, 17, 55, 2, 836000, tzinfo=tzlocal()),\n",
       " 'lastModifiedTimestamp': datetime.datetime(2024, 5, 8, 19, 9, 10, 345000, tzinfo=tzlocal()),\n",
       " 'status': 'ACTIVE'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wait for view to be ready\n",
    "wait_for_dataview_status(client=client, environmentId=ENV_ID, databaseName=DB_NAME, dataviewName=DBVIEW_NAME, show_wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33593bdf-ffd1-4df8-a94f-a60fa2dd9548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the HDB Cluster to use updated view of database\n",
    "resp=client.update_kx_cluster_databases(environmentId=ENV_ID, \n",
    "    clusterName=HDB_CLUSTER_NAME, \n",
    "    databases=[\n",
    "        {'databaseName': DB_NAME, 'dataviewName': DBVIEW_NAME}\n",
    "    ],\n",
    "    deploymentConfiguration={\n",
    "        'deploymentStrategy': 'ROLLING'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb15182b-f8e1-47ec-b7c1-84532b5cf304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: demo_hdb_cluster status is UPDATING, total wait 0:00:00, waiting 30 sec ...\n",
      "Cluster: demo_hdb_cluster status is UPDATING, total wait 0:00:30, waiting 30 sec ...\n",
      "Cluster: demo_hdb_cluster status is UPDATING, total wait 0:01:00, waiting 30 sec ...\n",
      "Cluster: demo_hdb_cluster status is UPDATING, total wait 0:01:30, waiting 30 sec ...\n",
      "Cluster: demo_hdb_cluster status is UPDATING, total wait 0:02:00, waiting 30 sec ...\n",
      "Cluster: demo_hdb_cluster status is UPDATING, total wait 0:02:30, waiting 30 sec ...\n",
      "Cluster: demo_hdb_cluster status is UPDATING, total wait 0:03:00, waiting 30 sec ...\n",
      "Cluster: demo_hdb_cluster status is UPDATING, total wait 0:03:30, waiting 30 sec ...\n",
      "Cluster: demo_hdb_cluster status is UPDATING, total wait 0:04:00, waiting 30 sec ...\n",
      "Cluster: demo_hdb_cluster status is UPDATING, total wait 0:04:30, waiting 30 sec ...\n",
      "Cluster: demo_hdb_cluster status is UPDATING, total wait 0:05:00, waiting 30 sec ...\n",
      "Cluster: demo_hdb_cluster status is UPDATING, total wait 0:05:30, waiting 30 sec ...\n",
      "Cluster: demo_hdb_cluster status is UPDATING, total wait 0:06:00, waiting 30 sec ...\n",
      "Cluster: demo_hdb_cluster status is UPDATING, total wait 0:06:30, waiting 30 sec ...\n",
      "Cluster: demo_hdb_cluster status is now RUNNING, total wait 0:07:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'status': 'RUNNING',\n",
       " 'clusterName': 'demo_hdb_cluster',\n",
       " 'clusterType': 'HDB',\n",
       " 'volumes': [{'volumeName': 'DEMO_SHARED_VOLUME', 'volumeType': 'NAS_1'}],\n",
       " 'databases': [{'databaseName': 'DEMO_DB',\n",
       "   'dataviewConfiguration': {'dataviewName': 'DEMO_DB_VIEW',\n",
       "    'dataviewVersionId': 'gMesyz37zA6bcFdXH7P71w',\n",
       "    'changesetId': 'YMesyucSrX60IrXKdemSzA',\n",
       "    'segmentConfigurations': [{'dbPaths': ['/*'],\n",
       "      'volumeName': 'DEMO_SHARED_VOLUME',\n",
       "      'onDemand': False}]}}],\n",
       " 'clusterDescription': 'Created with create_all notebook',\n",
       " 'releaseLabel': '1.0',\n",
       " 'vpcConfiguration': {'vpcId': 'vpc-0fe2b9c50f3ad382f',\n",
       "  'securityGroupIds': ['sg-0c99f1cfb9c3c7fd9'],\n",
       "  'subnetIds': ['subnet-04052219ec25b062b'],\n",
       "  'ipAddressType': 'IP_V4'},\n",
       " 'commandLineArguments': [{'key': 's', 'value': '4'}],\n",
       " 'executionRole': 'arn:aws:iam::829845998889:role/kdb-all-user',\n",
       " 'lastModifiedTimestamp': datetime.datetime(2024, 5, 8, 19, 15, 46, 726000, tzinfo=tzlocal()),\n",
       " 'azMode': 'SINGLE',\n",
       " 'availabilityZoneId': 'use1-az6',\n",
       " 'createdTimestamp': datetime.datetime(2024, 5, 8, 18, 1, 46, 429000, tzinfo=tzlocal()),\n",
       " 'scalingGroupConfiguration': {'scalingGroupName': 'DEMO_SCALING_GROUP',\n",
       "  'memoryLimit': 32768,\n",
       "  'memoryReservation': 6,\n",
       "  'nodeCount': 3}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wait for the HDB to update\n",
    "wait_for_cluster_status(client, environmentId=ENV_ID, clusterName=HDB_CLUSTER_NAME, show_wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3363563d-89a1-4342-ad8e-883911991184",
   "metadata": {},
   "source": [
    "# Query the HDB \n",
    "Show the new data by querying the tables in the HDB. The data has changed from the data that was just added to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d8a5da6-9e14-4456-8fd8-de2285072962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Tables and Counts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>taq</th>\n",
       "      <td>27360751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "pykx.Dictionary(pykx.q('taq| 27360751'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Table: taq\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>f</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>\"d\"</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <td>\"s\"</td>\n",
       "      <td></td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <td>\"n\"</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EventType</th>\n",
       "      <td>\"s\"</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>\"f\"</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quantity</th>\n",
       "      <td>\"j\"</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exchange</th>\n",
       "      <td>\"s\"</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conditions</th>\n",
       "      <td>\"s\"</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "pykx.KeyedTable(pykx.q('\n",
       "c         | t f a\n",
       "----------| -----\n",
       "date      | d    \n",
       "Ticker    | s   p\n",
       "Timestamp | n    \n",
       "EventType | s    \n",
       "Price     | f    \n",
       "Quantity  | j    \n",
       "Exchange  | s    \n",
       "Conditions| s    \n",
       "'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Conditions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021.01.05</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0D04:00:00.074828586</td>\n",
       "      <td>TRADE</td>\n",
       "      <td>130.07</td>\n",
       "      <td>639</td>\n",
       "      <td>ARCA</td>\n",
       "      <td>20000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021.01.05</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0D04:00:00.077890184</td>\n",
       "      <td>QUOTE BID</td>\n",
       "      <td>120f</td>\n",
       "      <td>100</td>\n",
       "      <td>ARCA</td>\n",
       "      <td>00000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021.01.05</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0D04:00:00.077890184</td>\n",
       "      <td>QUOTE ASK</td>\n",
       "      <td>0f</td>\n",
       "      <td>0</td>\n",
       "      <td>ARCA</td>\n",
       "      <td>00000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021.01.05</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0D04:00:00.077890184</td>\n",
       "      <td>QUOTE BID NB</td>\n",
       "      <td>120f</td>\n",
       "      <td>100</td>\n",
       "      <td>ARCA</td>\n",
       "      <td>00000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021.01.05</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0D04:00:00.077938515</td>\n",
       "      <td>QUOTE BID</td>\n",
       "      <td>123f</td>\n",
       "      <td>100</td>\n",
       "      <td>ARCA</td>\n",
       "      <td>00000001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "pykx.Table(pykx.q('\n",
       "date       Ticker Timestamp            EventType    Price  Quantity Exchange Conditions\n",
       "---------------------------------------------------------------------------------------\n",
       "2021.01.05 AAPL   0D04:00:00.074828586 TRADE        130.07 639      ARCA     20000401  \n",
       "2021.01.05 AAPL   0D04:00:00.077890184 QUOTE BID    120    100      ARCA     00000001  \n",
       "2021.01.05 AAPL   0D04:00:00.077890184 QUOTE ASK    0      0        ARCA     00000001  \n",
       "2021.01.05 AAPL   0D04:00:00.077890184 QUOTE BID NB 120    100      ARCA     00000001  \n",
       "2021.01.05 AAPL   0D04:00:00.077938515 QUOTE BID    123    100      ARCA     00000001  \n",
       "'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Conditions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "pykx.Table(pykx.q('\n",
       "date Ticker Timestamp EventType Price Quantity Exchange Conditions\n",
       "------------------------------------------------------------------\n",
       "'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021.01.05</th>\n",
       "      <td>27360751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "pykx.KeyedTable(pykx.q('\n",
       "date      | rows    \n",
       "----------| --------\n",
       "2021.01.05| 27360751\n",
       "'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2021.01.05</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>21186507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1685421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>1720887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>1550965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLX</th>\n",
       "      <td>1216971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "pykx.KeyedTable(pykx.q('\n",
       "date       Ticker| rows    \n",
       "-----------------| --------\n",
       "2021.01.05 AAPL  | 21186507\n",
       "2021.01.05 AMZN  | 1685421 \n",
       "2021.01.05 FB    | 1720887 \n",
       "2021.01.05 GOOG  | 1550965 \n",
       "2021.01.05 NFLX  | 1216971 \n",
       "'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Query the HDB for before state\n",
    "hdb = get_pykx_connection(client, \n",
    "                          environmentId=ENV_ID, clusterName=HDB_CLUSTER_NAME, \n",
    "                          userName=KDB_USERNAME, boto_session=session)\n",
    "\n",
    "tables = hdb(\"tables[]\").py()\n",
    "\n",
    "# inventory of tables in the database and rows in each\n",
    "print(80*'=')\n",
    "print(\"Tables and Counts\")\n",
    "display( hdb(\"tables[]!count each value each tables[]\") )\n",
    "\n",
    "# For each table: schema, and samples and counts\n",
    "for t in tables:\n",
    "    print(80*'=')\n",
    "    print (f'Table: {t}')\n",
    "    print(80*'-')\n",
    "    display( hdb(f\"meta {t}\") )\n",
    "    display( hdb(f\"select from {t} where date = min date, i<5\") )\n",
    "    display( hdb(f\"select from {t} where date = max date, i<5\") )\n",
    "    display( hdb(f\"select rows:count i by date from {t}\") )\n",
    "    display( hdb(f\"select rows:count i by date,Ticker from {t}\") )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fff8ca5-ac6f-428a-a135-584f6b8d54e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Run: 2024-05-08 19:16:17.983785\n"
     ]
    }
   ],
   "source": [
    "print( f\"Last Run: {datetime.datetime.now()}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf8045-ae15-4b60-b323-835ee9e44005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
